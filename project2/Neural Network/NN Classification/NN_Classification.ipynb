{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3265d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64985a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       0.0       3    male  22.0      1      0   7.2500        S\n",
       "1       1.0       1  female  38.0      1      0  71.2833        C\n",
       "2       1.0       3  female  26.0      0      0   7.9250        S\n",
       "3       1.0       1  female  35.0      1      0  53.1000        S\n",
       "4       0.0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1\n",
    "\n",
    "files = ['train.csv', 'test.csv']\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    df = pd.concat([df, data], axis=0)\n",
    "df.to_csv('titanic.csv', index=False)\n",
    "\n",
    "df.head()\n",
    "df.ndim\n",
    "df.shape\n",
    "df.columns\n",
    "\n",
    "df = df.loc[:, ~df.columns.isin(['Name', 'Ticket','Cabin','PassengerId'])]\n",
    "df = df.dropna()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd6b2e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1 continued\n",
    "x = df.drop('Survived',axis=1).copy()\n",
    "y = df['Survived'].copy()\n",
    "x.head()\n",
    "y.unique()\n",
    "\n",
    "x_encoded = pd.get_dummies(x,columns=['Sex','Embarked'])\n",
    "\n",
    "# x_np = x.values\n",
    "# y_np = y.values\n",
    "x_encoded = (np.asarray(x_encoded).astype('float32'))\n",
    "y = np.asarray(y).astype('float32')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_encoded,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c3c3ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "681e3f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/7zkwp1j916l4xty0z4xy6mgh0000gn/T/ipykernel_11954/2331109339.py:69: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_train=np.asarray(x_train).astype(np.int)\n",
      "/var/folders/lw/7zkwp1j916l4xty0z4xy6mgh0000gn/T/ipykernel_11954/2331109339.py:71: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train=np.asarray(y_train).astype(np.int)\n",
      "2023-04-29 16:12:30.960071: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 27ms/step - loss: 0.3911 - accuracy: 0.6086 - val_loss: 0.4438 - val_accuracy: 0.5562\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3911 - accuracy: 0.6086 - val_loss: 0.4438 - val_accuracy: 0.5562\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3911 - accuracy: 0.6086 - val_loss: 0.4438 - val_accuracy: 0.5562\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3911 - accuracy: 0.6086 - val_loss: 0.4438 - val_accuracy: 0.5562\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3910 - accuracy: 0.6086 - val_loss: 0.4438 - val_accuracy: 0.5562\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.3910 - accuracy: 0.6086 - val_loss: 0.4438 - val_accuracy: 0.5562\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3910 - accuracy: 0.6086 - val_loss: 0.4437 - val_accuracy: 0.5562\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3909 - accuracy: 0.6086 - val_loss: 0.4437 - val_accuracy: 0.5562\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3909 - accuracy: 0.6086 - val_loss: 0.4437 - val_accuracy: 0.5562\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.3908 - accuracy: 0.6086 - val_loss: 0.4437 - val_accuracy: 0.5562\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.3908 - accuracy: 0.6086 - val_loss: 0.4437 - val_accuracy: 0.5562\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3907 - accuracy: 0.6086 - val_loss: 0.4437 - val_accuracy: 0.5562\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3907 - accuracy: 0.6086 - val_loss: 0.4437 - val_accuracy: 0.5562\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3906 - accuracy: 0.6086 - val_loss: 0.4436 - val_accuracy: 0.5562\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3905 - accuracy: 0.6086 - val_loss: 0.4436 - val_accuracy: 0.5562\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3904 - accuracy: 0.6086 - val_loss: 0.4435 - val_accuracy: 0.5562\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3902 - accuracy: 0.6086 - val_loss: 0.4435 - val_accuracy: 0.5562\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3901 - accuracy: 0.6086 - val_loss: 0.4434 - val_accuracy: 0.5562\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3899 - accuracy: 0.6086 - val_loss: 0.4433 - val_accuracy: 0.5562\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3896 - accuracy: 0.6086 - val_loss: 0.4431 - val_accuracy: 0.5562\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3892 - accuracy: 0.6086 - val_loss: 0.4429 - val_accuracy: 0.5562\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3887 - accuracy: 0.6086 - val_loss: 0.4425 - val_accuracy: 0.5562\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.3880 - accuracy: 0.6086 - val_loss: 0.4419 - val_accuracy: 0.5562\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.3867 - accuracy: 0.6086 - val_loss: 0.4411 - val_accuracy: 0.5562\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3849 - accuracy: 0.6086 - val_loss: 0.4397 - val_accuracy: 0.5562\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3827 - accuracy: 0.6086 - val_loss: 0.4375 - val_accuracy: 0.5562\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3799 - accuracy: 0.6105 - val_loss: 0.4340 - val_accuracy: 0.5562\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3756 - accuracy: 0.6124 - val_loss: 0.4292 - val_accuracy: 0.5562\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3708 - accuracy: 0.6142 - val_loss: 0.4226 - val_accuracy: 0.5562\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3651 - accuracy: 0.6236 - val_loss: 0.4141 - val_accuracy: 0.5449\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3600 - accuracy: 0.6142 - val_loss: 0.4030 - val_accuracy: 0.5449\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3535 - accuracy: 0.6030 - val_loss: 0.3906 - val_accuracy: 0.5562\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3484 - accuracy: 0.6030 - val_loss: 0.3826 - val_accuracy: 0.5562\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3457 - accuracy: 0.6030 - val_loss: 0.3798 - val_accuracy: 0.5674\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3443 - accuracy: 0.6011 - val_loss: 0.3798 - val_accuracy: 0.5562\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3427 - accuracy: 0.6011 - val_loss: 0.3789 - val_accuracy: 0.5449\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3414 - accuracy: 0.6049 - val_loss: 0.3775 - val_accuracy: 0.5506\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3400 - accuracy: 0.6049 - val_loss: 0.3767 - val_accuracy: 0.5506\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3389 - accuracy: 0.6086 - val_loss: 0.3762 - val_accuracy: 0.5506\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3380 - accuracy: 0.6067 - val_loss: 0.3754 - val_accuracy: 0.5506\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3368 - accuracy: 0.6086 - val_loss: 0.3724 - val_accuracy: 0.5618\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3356 - accuracy: 0.6086 - val_loss: 0.3717 - val_accuracy: 0.5562\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3346 - accuracy: 0.6105 - val_loss: 0.3702 - val_accuracy: 0.5618\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3335 - accuracy: 0.6105 - val_loss: 0.3707 - val_accuracy: 0.5562\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3324 - accuracy: 0.6067 - val_loss: 0.3696 - val_accuracy: 0.5562\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3313 - accuracy: 0.6105 - val_loss: 0.3671 - val_accuracy: 0.5674\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3300 - accuracy: 0.6124 - val_loss: 0.3663 - val_accuracy: 0.5674\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3287 - accuracy: 0.6124 - val_loss: 0.3646 - val_accuracy: 0.5787\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3276 - accuracy: 0.6124 - val_loss: 0.3623 - val_accuracy: 0.5730\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3263 - accuracy: 0.6105 - val_loss: 0.3608 - val_accuracy: 0.5730\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3246 - accuracy: 0.6124 - val_loss: 0.3599 - val_accuracy: 0.5730\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3233 - accuracy: 0.6124 - val_loss: 0.3584 - val_accuracy: 0.5730\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3217 - accuracy: 0.6124 - val_loss: 0.3561 - val_accuracy: 0.5730\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3199 - accuracy: 0.6067 - val_loss: 0.3538 - val_accuracy: 0.5730\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3181 - accuracy: 0.6124 - val_loss: 0.3503 - val_accuracy: 0.5730\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3160 - accuracy: 0.6105 - val_loss: 0.3462 - val_accuracy: 0.5787\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3130 - accuracy: 0.6049 - val_loss: 0.3433 - val_accuracy: 0.5843\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3100 - accuracy: 0.6049 - val_loss: 0.3386 - val_accuracy: 0.5899\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3065 - accuracy: 0.6124 - val_loss: 0.3338 - val_accuracy: 0.5787\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3011 - accuracy: 0.6124 - val_loss: 0.3217 - val_accuracy: 0.5730\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2873 - accuracy: 0.6142 - val_loss: 0.2865 - val_accuracy: 0.5899\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2416 - accuracy: 0.6573 - val_loss: 0.2401 - val_accuracy: 0.7022\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2189 - accuracy: 0.7022 - val_loss: 0.2334 - val_accuracy: 0.6798\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2096 - accuracy: 0.7266 - val_loss: 0.2317 - val_accuracy: 0.6573\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2095 - accuracy: 0.7210 - val_loss: 0.2308 - val_accuracy: 0.6742\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.2072 - accuracy: 0.7210 - val_loss: 0.2299 - val_accuracy: 0.6798\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2045 - accuracy: 0.7266 - val_loss: 0.2274 - val_accuracy: 0.6742\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2030 - accuracy: 0.7247 - val_loss: 0.2244 - val_accuracy: 0.6742\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2009 - accuracy: 0.7285 - val_loss: 0.2234 - val_accuracy: 0.6798\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.2002 - accuracy: 0.7266 - val_loss: 0.2210 - val_accuracy: 0.6742\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1977 - accuracy: 0.7322 - val_loss: 0.2203 - val_accuracy: 0.6910\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.1962 - accuracy: 0.7285 - val_loss: 0.2178 - val_accuracy: 0.6910\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1939 - accuracy: 0.7303 - val_loss: 0.2148 - val_accuracy: 0.6854\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1926 - accuracy: 0.7378 - val_loss: 0.2133 - val_accuracy: 0.6854\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1906 - accuracy: 0.7378 - val_loss: 0.2121 - val_accuracy: 0.6910\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1898 - accuracy: 0.7360 - val_loss: 0.2118 - val_accuracy: 0.7022\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1870 - accuracy: 0.7303 - val_loss: 0.2085 - val_accuracy: 0.6798\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1857 - accuracy: 0.7341 - val_loss: 0.2069 - val_accuracy: 0.6910\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1840 - accuracy: 0.7360 - val_loss: 0.2056 - val_accuracy: 0.7135\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1823 - accuracy: 0.7322 - val_loss: 0.2044 - val_accuracy: 0.7191\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.1810 - accuracy: 0.7397 - val_loss: 0.2030 - val_accuracy: 0.7247\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1792 - accuracy: 0.7360 - val_loss: 0.2024 - val_accuracy: 0.7247\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1783 - accuracy: 0.7341 - val_loss: 0.2017 - val_accuracy: 0.7247\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1767 - accuracy: 0.7360 - val_loss: 0.1994 - val_accuracy: 0.7247\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1753 - accuracy: 0.7360 - val_loss: 0.1981 - val_accuracy: 0.7191\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1739 - accuracy: 0.7303 - val_loss: 0.1980 - val_accuracy: 0.7360\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1727 - accuracy: 0.7378 - val_loss: 0.1969 - val_accuracy: 0.7247\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1717 - accuracy: 0.7360 - val_loss: 0.1964 - val_accuracy: 0.7247\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1707 - accuracy: 0.7397 - val_loss: 0.1957 - val_accuracy: 0.7303\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1696 - accuracy: 0.7360 - val_loss: 0.1942 - val_accuracy: 0.7247\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1691 - accuracy: 0.7509 - val_loss: 0.1933 - val_accuracy: 0.7135\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1680 - accuracy: 0.7528 - val_loss: 0.1930 - val_accuracy: 0.7360\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1674 - accuracy: 0.7678 - val_loss: 0.1938 - val_accuracy: 0.7360\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1665 - accuracy: 0.7640 - val_loss: 0.1920 - val_accuracy: 0.7472\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1653 - accuracy: 0.7603 - val_loss: 0.1916 - val_accuracy: 0.7472\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.1647 - accuracy: 0.7678 - val_loss: 0.1915 - val_accuracy: 0.7528\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1640 - accuracy: 0.7640 - val_loss: 0.1909 - val_accuracy: 0.7472\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1633 - accuracy: 0.7622 - val_loss: 0.1903 - val_accuracy: 0.7472\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1630 - accuracy: 0.7528 - val_loss: 0.1899 - val_accuracy: 0.7528\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.1623 - accuracy: 0.7547 - val_loss: 0.1896 - val_accuracy: 0.7528\n"
     ]
    }
   ],
   "source": [
    "#question2\n",
    "\n",
    "def make_net2(number_features, \n",
    "             dropout=0.0, \n",
    "             learning_rate=0.003):\n",
    "    \n",
    "    \"\"\"Make TensorFlow neural net\"\"\"\n",
    "    \n",
    "    # Clear Tensorflow \n",
    "    K.clear_session()\n",
    "    \n",
    "    # Set up neural net\n",
    "    net = Sequential()\n",
    "    \n",
    "    \n",
    "    # Add final sigmoid activation output\n",
    "    net.add(Dense(1, activation='sigmoid'))    \n",
    "    \n",
    "    # Compiling model\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    \n",
    "    net.compile(loss='mean_squared_error', \n",
    "                optimizer=opt, \n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return net\n",
    "\n",
    "model2 = make_net2(10)\n",
    "#model2.summary()\n",
    "\n",
    "# def plot_training(history_dict):\n",
    "#     acc_values = history_dict['accuracy']\n",
    "#     val_acc_values = history_dict['val_accuracy']\n",
    "#     epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "#     plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "#     plt.plot(epochs, val_acc_values, 'b', label='Test accuracy')\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "def calculate_accuracy(model, X_train_sc, X_test_sc, y_train, y_test):\n",
    "    \"\"\"Calculate and print accuracy of trainign and test data fits\"\"\"    \n",
    "    \n",
    "    ### Get accuracy of fit to training data\n",
    "    probability = model.predict(X_train_sc)\n",
    "    y_pred_train = probability >= 0.5\n",
    "    y_pred_train = y_pred_train.flatten()\n",
    "    accuracy_train = np.mean(y_pred_train == y_train)\n",
    "    \n",
    "    ### Get accuracy of fit to test data\n",
    "    probability = model.predict(X_test_sc)\n",
    "    y_pred_test = probability >= 0.5\n",
    "    y_pred_test = y_pred_test.flatten()\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "\n",
    "    # Show acuracy\n",
    "    print (f'Training accuracy {accuracy_train:0.3f}')\n",
    "    print (f'Test accuracy {accuracy_test:0.3f}')\n",
    "    return y_pred_test\n",
    "    \n",
    "# Define network\n",
    "number_features = x_train.shape[1]\n",
    "model2 = make_net2(number_features)\n",
    "\n",
    "x_train=np.asarray(x_train).astype(np.int)\n",
    "\n",
    "y_train=np.asarray(y_train).astype(np.int)\n",
    "### Train model (and stote training info in history)\n",
    "history2 = model2.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7515213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Training accuracy 0.762\n",
      "Test accuracy 0.753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x28ddfdfc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#question 2 continued\n",
    "\n",
    "pred2 = calculate_accuracy(model2,x_train, x_test, y_train, y_test)\n",
    "#cm = Confusion_Matirx(y_test,pred2)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test,pred2))\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70140efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/7zkwp1j916l4xty0z4xy6mgh0000gn/T/ipykernel_11954/174079600.py:70: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_train=np.asarray(x_train).astype(np.int)\n",
      "/var/folders/lw/7zkwp1j916l4xty0z4xy6mgh0000gn/T/ipykernel_11954/174079600.py:72: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train=np.asarray(y_train).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 34ms/step - loss: 17.6628 - accuracy: 0.3914 - val_loss: 18.3939 - val_accuracy: 0.4438\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 17.3522 - accuracy: 0.3914 - val_loss: 18.0690 - val_accuracy: 0.4438\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 17.0355 - accuracy: 0.3914 - val_loss: 17.7465 - val_accuracy: 0.4438\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 16.7252 - accuracy: 0.3914 - val_loss: 17.4188 - val_accuracy: 0.4438\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 16.4103 - accuracy: 0.3914 - val_loss: 17.0928 - val_accuracy: 0.4438\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 16.1014 - accuracy: 0.3914 - val_loss: 16.7668 - val_accuracy: 0.4438\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 15.7956 - accuracy: 0.3914 - val_loss: 16.4401 - val_accuracy: 0.4438\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 15.4846 - accuracy: 0.3914 - val_loss: 16.1165 - val_accuracy: 0.4438\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 15.1695 - accuracy: 0.3914 - val_loss: 15.7914 - val_accuracy: 0.4438\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 14.8581 - accuracy: 0.3914 - val_loss: 15.4648 - val_accuracy: 0.4438\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 14.5471 - accuracy: 0.3914 - val_loss: 15.1389 - val_accuracy: 0.4438\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 14.2372 - accuracy: 0.3914 - val_loss: 14.8094 - val_accuracy: 0.4438\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 13.9234 - accuracy: 0.3914 - val_loss: 14.4842 - val_accuracy: 0.4438\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 13.6103 - accuracy: 0.3914 - val_loss: 14.1604 - val_accuracy: 0.4438\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 13.3025 - accuracy: 0.3914 - val_loss: 13.8360 - val_accuracy: 0.4438\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 12.9906 - accuracy: 0.3914 - val_loss: 13.5133 - val_accuracy: 0.4438\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 12.6827 - accuracy: 0.3914 - val_loss: 13.1902 - val_accuracy: 0.4438\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 12.3775 - accuracy: 0.3914 - val_loss: 12.8580 - val_accuracy: 0.4438\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 12.0573 - accuracy: 0.3914 - val_loss: 12.5344 - val_accuracy: 0.4438\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 11.7478 - accuracy: 0.3914 - val_loss: 12.2122 - val_accuracy: 0.4438\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 11.4449 - accuracy: 0.3914 - val_loss: 11.8796 - val_accuracy: 0.4438\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 11.1286 - accuracy: 0.3914 - val_loss: 11.5522 - val_accuracy: 0.4438\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 10.8128 - accuracy: 0.3914 - val_loss: 11.2337 - val_accuracy: 0.4438\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 10.5116 - accuracy: 0.3914 - val_loss: 10.9079 - val_accuracy: 0.4438\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 10.1986 - accuracy: 0.3895 - val_loss: 10.5828 - val_accuracy: 0.4438\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 9.8937 - accuracy: 0.3895 - val_loss: 10.2616 - val_accuracy: 0.4438\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 9.5876 - accuracy: 0.3895 - val_loss: 9.9428 - val_accuracy: 0.4438\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 9.2790 - accuracy: 0.3895 - val_loss: 9.6237 - val_accuracy: 0.4438\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 8.9792 - accuracy: 0.3914 - val_loss: 9.3019 - val_accuracy: 0.4438\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 8.6644 - accuracy: 0.3895 - val_loss: 8.9877 - val_accuracy: 0.4438\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 8.3643 - accuracy: 0.3895 - val_loss: 8.6577 - val_accuracy: 0.4382\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 8.0531 - accuracy: 0.3895 - val_loss: 8.3359 - val_accuracy: 0.4382\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 7.7416 - accuracy: 0.3895 - val_loss: 8.0220 - val_accuracy: 0.4382\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 7.4464 - accuracy: 0.3895 - val_loss: 7.6967 - val_accuracy: 0.4382\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 7.1337 - accuracy: 0.3895 - val_loss: 7.3818 - val_accuracy: 0.4382\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 6.8332 - accuracy: 0.3895 - val_loss: 7.0699 - val_accuracy: 0.4382\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 6.5322 - accuracy: 0.3858 - val_loss: 6.7560 - val_accuracy: 0.4382\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 6.2325 - accuracy: 0.3839 - val_loss: 6.4402 - val_accuracy: 0.4326\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 5.9292 - accuracy: 0.3764 - val_loss: 6.1259 - val_accuracy: 0.4326\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 5.6369 - accuracy: 0.3745 - val_loss: 5.8107 - val_accuracy: 0.4270\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 5.3360 - accuracy: 0.3708 - val_loss: 5.5008 - val_accuracy: 0.4270\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 5.0433 - accuracy: 0.3708 - val_loss: 5.2007 - val_accuracy: 0.4270\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 4.7531 - accuracy: 0.3708 - val_loss: 4.9098 - val_accuracy: 0.4326\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 4.4774 - accuracy: 0.3708 - val_loss: 4.6153 - val_accuracy: 0.4382\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 4.1960 - accuracy: 0.3708 - val_loss: 4.3222 - val_accuracy: 0.4270\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 3.9147 - accuracy: 0.3708 - val_loss: 4.0421 - val_accuracy: 0.4270\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 3.6561 - accuracy: 0.3708 - val_loss: 3.7610 - val_accuracy: 0.4213\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 3.3944 - accuracy: 0.3652 - val_loss: 3.4924 - val_accuracy: 0.4157\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 3.1446 - accuracy: 0.3745 - val_loss: 3.2377 - val_accuracy: 0.4213\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 2.9029 - accuracy: 0.3801 - val_loss: 2.9937 - val_accuracy: 0.4157\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.6709 - accuracy: 0.3933 - val_loss: 2.7581 - val_accuracy: 0.4157\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 2.4550 - accuracy: 0.4176 - val_loss: 2.5308 - val_accuracy: 0.4326\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.2546 - accuracy: 0.4438 - val_loss: 2.3148 - val_accuracy: 0.4438\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 2.0626 - accuracy: 0.4625 - val_loss: 2.1192 - val_accuracy: 0.4663\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.8875 - accuracy: 0.4775 - val_loss: 1.9456 - val_accuracy: 0.4831\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.7317 - accuracy: 0.4981 - val_loss: 1.7837 - val_accuracy: 0.4775\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.5882 - accuracy: 0.5075 - val_loss: 1.6398 - val_accuracy: 0.4831\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.4645 - accuracy: 0.5169 - val_loss: 1.5122 - val_accuracy: 0.5056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.3572 - accuracy: 0.5449 - val_loss: 1.4101 - val_accuracy: 0.4944\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.2636 - accuracy: 0.5581 - val_loss: 1.3300 - val_accuracy: 0.5056\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1973 - accuracy: 0.5543 - val_loss: 1.2656 - val_accuracy: 0.5169\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1414 - accuracy: 0.5581 - val_loss: 1.2214 - val_accuracy: 0.5112\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.1035 - accuracy: 0.5637 - val_loss: 1.1913 - val_accuracy: 0.5056\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0720 - accuracy: 0.5674 - val_loss: 1.1686 - val_accuracy: 0.5112\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0484 - accuracy: 0.5768 - val_loss: 1.1470 - val_accuracy: 0.5112\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0267 - accuracy: 0.5787 - val_loss: 1.1274 - val_accuracy: 0.5112\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0055 - accuracy: 0.5861 - val_loss: 1.1094 - val_accuracy: 0.5169\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9873 - accuracy: 0.5918 - val_loss: 1.0927 - val_accuracy: 0.5169\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.9703 - accuracy: 0.5974 - val_loss: 1.0779 - val_accuracy: 0.5393\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.9546 - accuracy: 0.6049 - val_loss: 1.0649 - val_accuracy: 0.5449\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9410 - accuracy: 0.6105 - val_loss: 1.0528 - val_accuracy: 0.5562\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9286 - accuracy: 0.6142 - val_loss: 1.0414 - val_accuracy: 0.5562\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9160 - accuracy: 0.6142 - val_loss: 1.0312 - val_accuracy: 0.5562\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.9054 - accuracy: 0.6161 - val_loss: 1.0215 - val_accuracy: 0.5562\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.8953 - accuracy: 0.6217 - val_loss: 1.0127 - val_accuracy: 0.5562\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.8862 - accuracy: 0.6292 - val_loss: 1.0052 - val_accuracy: 0.5562\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8781 - accuracy: 0.6292 - val_loss: 0.9980 - val_accuracy: 0.5618\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.8698 - accuracy: 0.6367 - val_loss: 0.9913 - val_accuracy: 0.5618\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.8632 - accuracy: 0.6461 - val_loss: 0.9848 - val_accuracy: 0.5674\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8561 - accuracy: 0.6423 - val_loss: 0.9787 - val_accuracy: 0.5843\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.8495 - accuracy: 0.6404 - val_loss: 0.9730 - val_accuracy: 0.5899\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.8433 - accuracy: 0.6404 - val_loss: 0.9683 - val_accuracy: 0.5843\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.8372 - accuracy: 0.6423 - val_loss: 0.9639 - val_accuracy: 0.5843\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8325 - accuracy: 0.6479 - val_loss: 0.9589 - val_accuracy: 0.5787\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.8267 - accuracy: 0.6498 - val_loss: 0.9542 - val_accuracy: 0.5787\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.8220 - accuracy: 0.6517 - val_loss: 0.9498 - val_accuracy: 0.5787\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.8176 - accuracy: 0.6536 - val_loss: 0.9463 - val_accuracy: 0.5787\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.8129 - accuracy: 0.6573 - val_loss: 0.9420 - val_accuracy: 0.5843\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8085 - accuracy: 0.6573 - val_loss: 0.9380 - val_accuracy: 0.5843\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8043 - accuracy: 0.6554 - val_loss: 0.9339 - val_accuracy: 0.5843\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.8010 - accuracy: 0.6592 - val_loss: 0.9300 - val_accuracy: 0.5843\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7967 - accuracy: 0.6573 - val_loss: 0.9270 - val_accuracy: 0.5843\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7930 - accuracy: 0.6610 - val_loss: 0.9246 - val_accuracy: 0.5843\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7893 - accuracy: 0.6648 - val_loss: 0.9219 - val_accuracy: 0.5899\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7858 - accuracy: 0.6704 - val_loss: 0.9192 - val_accuracy: 0.5955\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7823 - accuracy: 0.6723 - val_loss: 0.9165 - val_accuracy: 0.5899\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7788 - accuracy: 0.6723 - val_loss: 0.9137 - val_accuracy: 0.5843\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7756 - accuracy: 0.6723 - val_loss: 0.9107 - val_accuracy: 0.5843\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7721 - accuracy: 0.6704 - val_loss: 0.9078 - val_accuracy: 0.5843\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7690 - accuracy: 0.6704 - val_loss: 0.9041 - val_accuracy: 0.5843\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7653 - accuracy: 0.6723 - val_loss: 0.9015 - val_accuracy: 0.5843\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7623 - accuracy: 0.6742 - val_loss: 0.8990 - val_accuracy: 0.5843\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7593 - accuracy: 0.6742 - val_loss: 0.8962 - val_accuracy: 0.5899\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7562 - accuracy: 0.6723 - val_loss: 0.8933 - val_accuracy: 0.5899\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7532 - accuracy: 0.6723 - val_loss: 0.8906 - val_accuracy: 0.5955\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7503 - accuracy: 0.6742 - val_loss: 0.8880 - val_accuracy: 0.6011\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7471 - accuracy: 0.6779 - val_loss: 0.8846 - val_accuracy: 0.6067\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7447 - accuracy: 0.6723 - val_loss: 0.8797 - val_accuracy: 0.6011\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7412 - accuracy: 0.6723 - val_loss: 0.8766 - val_accuracy: 0.6011\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7384 - accuracy: 0.6723 - val_loss: 0.8747 - val_accuracy: 0.6067\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7357 - accuracy: 0.6704 - val_loss: 0.8713 - val_accuracy: 0.6067\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.7327 - accuracy: 0.6760 - val_loss: 0.8703 - val_accuracy: 0.6067\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7298 - accuracy: 0.6760 - val_loss: 0.8684 - val_accuracy: 0.6124\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7269 - accuracy: 0.6760 - val_loss: 0.8644 - val_accuracy: 0.6180\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7238 - accuracy: 0.6742 - val_loss: 0.8603 - val_accuracy: 0.6067\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7219 - accuracy: 0.6742 - val_loss: 0.8560 - val_accuracy: 0.6067\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7191 - accuracy: 0.6723 - val_loss: 0.8529 - val_accuracy: 0.6067\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7163 - accuracy: 0.6760 - val_loss: 0.8507 - val_accuracy: 0.6067\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7134 - accuracy: 0.6779 - val_loss: 0.8485 - val_accuracy: 0.6124\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.7107 - accuracy: 0.6779 - val_loss: 0.8464 - val_accuracy: 0.6180\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7086 - accuracy: 0.6835 - val_loss: 0.8453 - val_accuracy: 0.6236\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7056 - accuracy: 0.6798 - val_loss: 0.8421 - val_accuracy: 0.6236\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7034 - accuracy: 0.6835 - val_loss: 0.8393 - val_accuracy: 0.6236\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.7003 - accuracy: 0.6873 - val_loss: 0.8376 - val_accuracy: 0.6236\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6980 - accuracy: 0.6873 - val_loss: 0.8353 - val_accuracy: 0.6292\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6955 - accuracy: 0.6891 - val_loss: 0.8333 - val_accuracy: 0.6292\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6936 - accuracy: 0.6891 - val_loss: 0.8299 - val_accuracy: 0.6292\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.6891 - val_loss: 0.8279 - val_accuracy: 0.6292\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6883 - accuracy: 0.6891 - val_loss: 0.8257 - val_accuracy: 0.6292\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6858 - accuracy: 0.6891 - val_loss: 0.8217 - val_accuracy: 0.6292\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6838 - accuracy: 0.6873 - val_loss: 0.8189 - val_accuracy: 0.6292\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6816 - accuracy: 0.6891 - val_loss: 0.8153 - val_accuracy: 0.6292\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6791 - accuracy: 0.6910 - val_loss: 0.8138 - val_accuracy: 0.6292\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6767 - accuracy: 0.6910 - val_loss: 0.8126 - val_accuracy: 0.6292\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6741 - accuracy: 0.6910 - val_loss: 0.8104 - val_accuracy: 0.6292\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6718 - accuracy: 0.6929 - val_loss: 0.8087 - val_accuracy: 0.6292\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6695 - accuracy: 0.6929 - val_loss: 0.8060 - val_accuracy: 0.6292\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6675 - accuracy: 0.6929 - val_loss: 0.8031 - val_accuracy: 0.6292\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6655 - accuracy: 0.6948 - val_loss: 0.8022 - val_accuracy: 0.6292\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6627 - accuracy: 0.6929 - val_loss: 0.7985 - val_accuracy: 0.6348\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6610 - accuracy: 0.6948 - val_loss: 0.7954 - val_accuracy: 0.6348\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6588 - accuracy: 0.6985 - val_loss: 0.7944 - val_accuracy: 0.6348\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6571 - accuracy: 0.6929 - val_loss: 0.7902 - val_accuracy: 0.6348\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6546 - accuracy: 0.6910 - val_loss: 0.7890 - val_accuracy: 0.6348\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6522 - accuracy: 0.6910 - val_loss: 0.7872 - val_accuracy: 0.6348\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6502 - accuracy: 0.6948 - val_loss: 0.7863 - val_accuracy: 0.6348\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6482 - accuracy: 0.6966 - val_loss: 0.7843 - val_accuracy: 0.6348\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6465 - accuracy: 0.6910 - val_loss: 0.7801 - val_accuracy: 0.6348\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6440 - accuracy: 0.6929 - val_loss: 0.7777 - val_accuracy: 0.6348\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6419 - accuracy: 0.6929 - val_loss: 0.7756 - val_accuracy: 0.6348\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6405 - accuracy: 0.6948 - val_loss: 0.7745 - val_accuracy: 0.6348\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6380 - accuracy: 0.6948 - val_loss: 0.7707 - val_accuracy: 0.6348\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6364 - accuracy: 0.6929 - val_loss: 0.7677 - val_accuracy: 0.6404\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6344 - accuracy: 0.6929 - val_loss: 0.7661 - val_accuracy: 0.6404\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6325 - accuracy: 0.6948 - val_loss: 0.7648 - val_accuracy: 0.6404\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6312 - accuracy: 0.6948 - val_loss: 0.7622 - val_accuracy: 0.6348\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6293 - accuracy: 0.6948 - val_loss: 0.7619 - val_accuracy: 0.6292\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6270 - accuracy: 0.6948 - val_loss: 0.7603 - val_accuracy: 0.6292\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6253 - accuracy: 0.6966 - val_loss: 0.7585 - val_accuracy: 0.6292\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6236 - accuracy: 0.6966 - val_loss: 0.7568 - val_accuracy: 0.6236\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6221 - accuracy: 0.6948 - val_loss: 0.7535 - val_accuracy: 0.6348\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.6199 - accuracy: 0.6966 - val_loss: 0.7511 - val_accuracy: 0.6404\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6184 - accuracy: 0.6966 - val_loss: 0.7490 - val_accuracy: 0.6404\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6165 - accuracy: 0.6966 - val_loss: 0.7481 - val_accuracy: 0.6404\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6147 - accuracy: 0.6966 - val_loss: 0.7465 - val_accuracy: 0.6348\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6134 - accuracy: 0.6985 - val_loss: 0.7456 - val_accuracy: 0.6292\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6125 - accuracy: 0.7004 - val_loss: 0.7419 - val_accuracy: 0.6461\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6097 - accuracy: 0.6985 - val_loss: 0.7404 - val_accuracy: 0.6348\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6080 - accuracy: 0.7004 - val_loss: 0.7398 - val_accuracy: 0.6292\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6064 - accuracy: 0.7022 - val_loss: 0.7367 - val_accuracy: 0.6348\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6051 - accuracy: 0.7041 - val_loss: 0.7363 - val_accuracy: 0.6292\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6040 - accuracy: 0.7022 - val_loss: 0.7327 - val_accuracy: 0.6404\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6013 - accuracy: 0.7097 - val_loss: 0.7318 - val_accuracy: 0.6404\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6000 - accuracy: 0.7079 - val_loss: 0.7310 - val_accuracy: 0.6236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5988 - accuracy: 0.7116 - val_loss: 0.7272 - val_accuracy: 0.6404\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5967 - accuracy: 0.7135 - val_loss: 0.7261 - val_accuracy: 0.6348\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5954 - accuracy: 0.7154 - val_loss: 0.7252 - val_accuracy: 0.6348\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5938 - accuracy: 0.7135 - val_loss: 0.7234 - val_accuracy: 0.6348\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5923 - accuracy: 0.7154 - val_loss: 0.7197 - val_accuracy: 0.6404\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5911 - accuracy: 0.7135 - val_loss: 0.7184 - val_accuracy: 0.6404\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5890 - accuracy: 0.7116 - val_loss: 0.7152 - val_accuracy: 0.6404\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5896 - accuracy: 0.7079 - val_loss: 0.7122 - val_accuracy: 0.6461\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5879 - accuracy: 0.7154 - val_loss: 0.7129 - val_accuracy: 0.6348\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5849 - accuracy: 0.7135 - val_loss: 0.7113 - val_accuracy: 0.6348\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5833 - accuracy: 0.7135 - val_loss: 0.7089 - val_accuracy: 0.6348\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5824 - accuracy: 0.7191 - val_loss: 0.7058 - val_accuracy: 0.6404\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5807 - accuracy: 0.7154 - val_loss: 0.7045 - val_accuracy: 0.6404\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5796 - accuracy: 0.7135 - val_loss: 0.7034 - val_accuracy: 0.6348\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5793 - accuracy: 0.7097 - val_loss: 0.7003 - val_accuracy: 0.6517\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.5770 - accuracy: 0.7172 - val_loss: 0.6992 - val_accuracy: 0.6461\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5756 - accuracy: 0.7172 - val_loss: 0.6978 - val_accuracy: 0.6348\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5738 - accuracy: 0.7210 - val_loss: 0.6974 - val_accuracy: 0.6461\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5724 - accuracy: 0.7247 - val_loss: 0.6963 - val_accuracy: 0.6461\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5709 - accuracy: 0.7247 - val_loss: 0.6946 - val_accuracy: 0.6461\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5698 - accuracy: 0.7191 - val_loss: 0.6928 - val_accuracy: 0.6461\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5686 - accuracy: 0.7191 - val_loss: 0.6926 - val_accuracy: 0.6461\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5670 - accuracy: 0.7172 - val_loss: 0.6912 - val_accuracy: 0.6461\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5658 - accuracy: 0.7191 - val_loss: 0.6894 - val_accuracy: 0.6461\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5645 - accuracy: 0.7191 - val_loss: 0.6891 - val_accuracy: 0.6517\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5633 - accuracy: 0.7154 - val_loss: 0.6861 - val_accuracy: 0.6517\n"
     ]
    }
   ],
   "source": [
    "#question 3\n",
    "\n",
    "def make_net3(number_features, \n",
    "             hidden_layers=1, \n",
    "             hidden_layer_neurones=0, \n",
    "             dropout=0.0, \n",
    "             learning_rate=0.003):\n",
    "    \n",
    "    \"\"\"Make TensorFlow neural net\"\"\"\n",
    "    \n",
    "    # Clear Tensorflow \n",
    "    K.clear_session()\n",
    "    \n",
    "    # Set up neural net\n",
    "    net = Sequential()\n",
    "    \n",
    "    \n",
    "    # Add final sigmoid activation output\n",
    "    net.add(Dense(1, activation='sigmoid'))    \n",
    "    \n",
    "    # Compiling model\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    \n",
    "    net.compile(loss='binary_crossentropy', \n",
    "                optimizer=opt, \n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return net\n",
    "\n",
    "model3 = make_net3(10)\n",
    "#model3.summary()\n",
    "\n",
    "# def plot_training(history_dict):\n",
    "#     acc_values = history_dict['accuracy']\n",
    "#     val_acc_values = history_dict['val_accuracy']\n",
    "#     epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "#     plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "#     plt.plot(epochs, val_acc_values, 'b', label='Test accuracy')\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "def calculate_accuracy(model, X_train_sc, X_test_sc, y_train, y_test):\n",
    "    \"\"\"Calculate and print accuracy of trainign and test data fits\"\"\"    \n",
    "    \n",
    "    ### Get accuracy of fit to training data\n",
    "    probability = model.predict(X_train_sc)\n",
    "    y_pred_train = probability >= 0.5\n",
    "    y_pred_train = y_pred_train.flatten()\n",
    "    accuracy_train = np.mean(y_pred_train == y_train)\n",
    "    \n",
    "    ### Get accuracy of fit to test data\n",
    "    probability = model.predict(X_test_sc)\n",
    "    y_pred_test = probability >= 0.5\n",
    "    y_pred_test = y_pred_test.flatten()\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "\n",
    "    # Show acuracy\n",
    "    print (f'Training accuracy {accuracy_train:0.3f}')\n",
    "    print (f'Test accuracy {accuracy_test:0.3f}')\n",
    "    return y_pred_test\n",
    "# Define network\n",
    "number_features = x_train.shape[1]\n",
    "model3 = make_net3(number_features)\n",
    "\n",
    "x_train=np.asarray(x_train).astype(np.int)\n",
    "\n",
    "y_train=np.asarray(y_train).astype(np.int)\n",
    "### Train model (and stote training info in history)\n",
    "history3 = model3.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "608e46ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "Training accuracy 0.717\n",
      "Test accuracy 0.652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x28f4e6e00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#question continued\n",
    "pred3 = calculate_accuracy(model3,x_train, x_test, y_train, y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test,pred3))\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8d9ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishnuteja/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4 logistic regression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b278456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy 0.807\n",
      "Test accuracy 0.792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1079bfac0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = log_reg.predict(x_test)\n",
    "pred4 = calculate_accuracy(log_reg,x_train, x_test, y_train, y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test,pred4))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d7f939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After comparing the accuracies, the model in question better resembles the logistice regression model\n"
     ]
    }
   ],
   "source": [
    "print(\"After comparing the accuracies, the model in question better resembles the logistice regression model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4c9e4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/7zkwp1j916l4xty0z4xy6mgh0000gn/T/ipykernel_11954/1411032668.py:79: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_train=np.asarray(x_train).astype(np.int)\n",
      "/var/folders/lw/7zkwp1j916l4xty0z4xy6mgh0000gn/T/ipykernel_11954/1411032668.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train=np.asarray(y_train).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 46ms/step - loss: 0.8124 - accuracy: 0.3914 - val_loss: 0.7696 - val_accuracy: 0.4438\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.8057 - accuracy: 0.3914 - val_loss: 0.7638 - val_accuracy: 0.4438\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7988 - accuracy: 0.3914 - val_loss: 0.7582 - val_accuracy: 0.4438\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.7922 - accuracy: 0.3914 - val_loss: 0.7530 - val_accuracy: 0.4438\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7859 - accuracy: 0.3914 - val_loss: 0.7481 - val_accuracy: 0.4438\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.7795 - accuracy: 0.3914 - val_loss: 0.7436 - val_accuracy: 0.4438\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.7734 - accuracy: 0.3914 - val_loss: 0.7393 - val_accuracy: 0.4438\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7672 - accuracy: 0.3914 - val_loss: 0.7353 - val_accuracy: 0.4438\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7609 - accuracy: 0.3914 - val_loss: 0.7316 - val_accuracy: 0.4438\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7550 - accuracy: 0.3914 - val_loss: 0.7281 - val_accuracy: 0.4438\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7492 - accuracy: 0.3914 - val_loss: 0.7246 - val_accuracy: 0.4438\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7433 - accuracy: 0.3914 - val_loss: 0.7216 - val_accuracy: 0.4438\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7382 - accuracy: 0.3914 - val_loss: 0.7185 - val_accuracy: 0.4438\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7331 - accuracy: 0.3914 - val_loss: 0.7157 - val_accuracy: 0.4438\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.7286 - accuracy: 0.3914 - val_loss: 0.7129 - val_accuracy: 0.4438\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.7240 - accuracy: 0.3652 - val_loss: 0.7102 - val_accuracy: 0.3933\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.7194 - accuracy: 0.3558 - val_loss: 0.7076 - val_accuracy: 0.3989\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7151 - accuracy: 0.3614 - val_loss: 0.7052 - val_accuracy: 0.4101\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7111 - accuracy: 0.3783 - val_loss: 0.7027 - val_accuracy: 0.4382\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.7069 - accuracy: 0.4139 - val_loss: 0.7006 - val_accuracy: 0.4382\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.7035 - accuracy: 0.4382 - val_loss: 0.6985 - val_accuracy: 0.4775\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6998 - accuracy: 0.4682 - val_loss: 0.6965 - val_accuracy: 0.5056\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6965 - accuracy: 0.4906 - val_loss: 0.6949 - val_accuracy: 0.5169\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.6934 - accuracy: 0.5225 - val_loss: 0.6934 - val_accuracy: 0.5225\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6906 - accuracy: 0.5431 - val_loss: 0.6922 - val_accuracy: 0.5337\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6882 - accuracy: 0.5618 - val_loss: 0.6913 - val_accuracy: 0.5393\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6858 - accuracy: 0.5730 - val_loss: 0.6906 - val_accuracy: 0.5393\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6838 - accuracy: 0.5880 - val_loss: 0.6899 - val_accuracy: 0.5393\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6818 - accuracy: 0.5955 - val_loss: 0.6894 - val_accuracy: 0.5449\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6802 - accuracy: 0.5955 - val_loss: 0.6887 - val_accuracy: 0.5449\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6786 - accuracy: 0.5955 - val_loss: 0.6878 - val_accuracy: 0.5449\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6772 - accuracy: 0.5993 - val_loss: 0.6874 - val_accuracy: 0.5506\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6760 - accuracy: 0.6030 - val_loss: 0.6870 - val_accuracy: 0.5506\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6749 - accuracy: 0.6011 - val_loss: 0.6866 - val_accuracy: 0.5506\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6740 - accuracy: 0.6011 - val_loss: 0.6860 - val_accuracy: 0.5506\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6730 - accuracy: 0.6011 - val_loss: 0.6854 - val_accuracy: 0.5506\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6721 - accuracy: 0.6067 - val_loss: 0.6850 - val_accuracy: 0.5562\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.6713 - accuracy: 0.6086 - val_loss: 0.6846 - val_accuracy: 0.5562\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6699 - accuracy: 0.6086 - val_loss: 0.6840 - val_accuracy: 0.5562\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6683 - accuracy: 0.6086 - val_loss: 0.6828 - val_accuracy: 0.5562\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6669 - accuracy: 0.6086 - val_loss: 0.6819 - val_accuracy: 0.5562\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6659 - accuracy: 0.6086 - val_loss: 0.6814 - val_accuracy: 0.5562\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6651 - accuracy: 0.6086 - val_loss: 0.6809 - val_accuracy: 0.5562\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6642 - accuracy: 0.6086 - val_loss: 0.6803 - val_accuracy: 0.5562\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6632 - accuracy: 0.6086 - val_loss: 0.6797 - val_accuracy: 0.5562\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6622 - accuracy: 0.6086 - val_loss: 0.6789 - val_accuracy: 0.5562\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6611 - accuracy: 0.6086 - val_loss: 0.6780 - val_accuracy: 0.5562\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6598 - accuracy: 0.6086 - val_loss: 0.6772 - val_accuracy: 0.5562\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6587 - accuracy: 0.6086 - val_loss: 0.6765 - val_accuracy: 0.5562\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6579 - accuracy: 0.6086 - val_loss: 0.6759 - val_accuracy: 0.5562\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6570 - accuracy: 0.6086 - val_loss: 0.6754 - val_accuracy: 0.5562\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6564 - accuracy: 0.6086 - val_loss: 0.6748 - val_accuracy: 0.5562\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6556 - accuracy: 0.6086 - val_loss: 0.6745 - val_accuracy: 0.5562\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6548 - accuracy: 0.6086 - val_loss: 0.6742 - val_accuracy: 0.5562\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6543 - accuracy: 0.6086 - val_loss: 0.6741 - val_accuracy: 0.5562\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6535 - accuracy: 0.6086 - val_loss: 0.6736 - val_accuracy: 0.5562\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6529 - accuracy: 0.6086 - val_loss: 0.6732 - val_accuracy: 0.5562\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6523 - accuracy: 0.6086 - val_loss: 0.6726 - val_accuracy: 0.5562\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6518 - accuracy: 0.6086 - val_loss: 0.6721 - val_accuracy: 0.5562\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6512 - accuracy: 0.6086 - val_loss: 0.6718 - val_accuracy: 0.5562\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6506 - accuracy: 0.6086 - val_loss: 0.6715 - val_accuracy: 0.5562\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6500 - accuracy: 0.6086 - val_loss: 0.6712 - val_accuracy: 0.5562\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6495 - accuracy: 0.6086 - val_loss: 0.6708 - val_accuracy: 0.5562\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6490 - accuracy: 0.6086 - val_loss: 0.6707 - val_accuracy: 0.5562\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6484 - accuracy: 0.6086 - val_loss: 0.6703 - val_accuracy: 0.5562\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6479 - accuracy: 0.6086 - val_loss: 0.6699 - val_accuracy: 0.5562\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6474 - accuracy: 0.6086 - val_loss: 0.6693 - val_accuracy: 0.5562\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6469 - accuracy: 0.6086 - val_loss: 0.6690 - val_accuracy: 0.5562\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6464 - accuracy: 0.6086 - val_loss: 0.6686 - val_accuracy: 0.5562\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 0.6459 - accuracy: 0.6086 - val_loss: 0.6682 - val_accuracy: 0.5562\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.6454 - accuracy: 0.6086 - val_loss: 0.6678 - val_accuracy: 0.5562\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6449 - accuracy: 0.6086 - val_loss: 0.6674 - val_accuracy: 0.5562\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6445 - accuracy: 0.6086 - val_loss: 0.6671 - val_accuracy: 0.5562\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6439 - accuracy: 0.6086 - val_loss: 0.6666 - val_accuracy: 0.5562\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6434 - accuracy: 0.6086 - val_loss: 0.6663 - val_accuracy: 0.5562\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6428 - accuracy: 0.6086 - val_loss: 0.6659 - val_accuracy: 0.5562\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6422 - accuracy: 0.6086 - val_loss: 0.6656 - val_accuracy: 0.5562\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6417 - accuracy: 0.6086 - val_loss: 0.6654 - val_accuracy: 0.5562\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.6411 - accuracy: 0.6086 - val_loss: 0.6652 - val_accuracy: 0.5562\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6406 - accuracy: 0.6086 - val_loss: 0.6649 - val_accuracy: 0.5562\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6400 - accuracy: 0.6086 - val_loss: 0.6647 - val_accuracy: 0.5562\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6394 - accuracy: 0.6086 - val_loss: 0.6644 - val_accuracy: 0.5562\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6388 - accuracy: 0.6086 - val_loss: 0.6641 - val_accuracy: 0.5562\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6382 - accuracy: 0.6086 - val_loss: 0.6640 - val_accuracy: 0.5562\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6376 - accuracy: 0.6086 - val_loss: 0.6638 - val_accuracy: 0.5562\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6370 - accuracy: 0.6086 - val_loss: 0.6636 - val_accuracy: 0.5562\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6365 - accuracy: 0.6086 - val_loss: 0.6632 - val_accuracy: 0.5562\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6359 - accuracy: 0.6086 - val_loss: 0.6629 - val_accuracy: 0.5562\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6354 - accuracy: 0.6086 - val_loss: 0.6626 - val_accuracy: 0.5562\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6348 - accuracy: 0.6086 - val_loss: 0.6623 - val_accuracy: 0.5562\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6342 - accuracy: 0.6086 - val_loss: 0.6619 - val_accuracy: 0.5562\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6336 - accuracy: 0.6086 - val_loss: 0.6616 - val_accuracy: 0.5562\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6331 - accuracy: 0.6086 - val_loss: 0.6613 - val_accuracy: 0.5562\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6324 - accuracy: 0.6086 - val_loss: 0.6609 - val_accuracy: 0.5562\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6319 - accuracy: 0.6086 - val_loss: 0.6605 - val_accuracy: 0.5562\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6312 - accuracy: 0.6086 - val_loss: 0.6602 - val_accuracy: 0.5562\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6307 - accuracy: 0.6086 - val_loss: 0.6598 - val_accuracy: 0.5562\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6301 - accuracy: 0.6086 - val_loss: 0.6594 - val_accuracy: 0.5562\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6294 - accuracy: 0.6086 - val_loss: 0.6590 - val_accuracy: 0.5562\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6288 - accuracy: 0.6086 - val_loss: 0.6586 - val_accuracy: 0.5562\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6282 - accuracy: 0.6086 - val_loss: 0.6581 - val_accuracy: 0.5562\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6276 - accuracy: 0.6086 - val_loss: 0.6577 - val_accuracy: 0.5562\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6269 - accuracy: 0.6086 - val_loss: 0.6573 - val_accuracy: 0.5562\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6264 - accuracy: 0.6086 - val_loss: 0.6568 - val_accuracy: 0.5562\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6257 - accuracy: 0.6086 - val_loss: 0.6564 - val_accuracy: 0.5562\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6251 - accuracy: 0.6086 - val_loss: 0.6561 - val_accuracy: 0.5562\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6244 - accuracy: 0.6086 - val_loss: 0.6557 - val_accuracy: 0.5562\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6239 - accuracy: 0.6086 - val_loss: 0.6553 - val_accuracy: 0.5562\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6232 - accuracy: 0.6086 - val_loss: 0.6549 - val_accuracy: 0.5562\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6226 - accuracy: 0.6086 - val_loss: 0.6545 - val_accuracy: 0.5562\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6219 - accuracy: 0.6086 - val_loss: 0.6540 - val_accuracy: 0.5562\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6212 - accuracy: 0.6086 - val_loss: 0.6534 - val_accuracy: 0.5562\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6205 - accuracy: 0.6086 - val_loss: 0.6530 - val_accuracy: 0.5562\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6200 - accuracy: 0.6086 - val_loss: 0.6524 - val_accuracy: 0.5562\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6192 - accuracy: 0.6086 - val_loss: 0.6521 - val_accuracy: 0.5562\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6185 - accuracy: 0.6086 - val_loss: 0.6515 - val_accuracy: 0.5562\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6179 - accuracy: 0.6086 - val_loss: 0.6511 - val_accuracy: 0.5562\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6172 - accuracy: 0.6086 - val_loss: 0.6505 - val_accuracy: 0.5562\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6166 - accuracy: 0.6086 - val_loss: 0.6499 - val_accuracy: 0.5562\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6158 - accuracy: 0.6086 - val_loss: 0.6495 - val_accuracy: 0.5562\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6152 - accuracy: 0.6086 - val_loss: 0.6489 - val_accuracy: 0.5562\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6145 - accuracy: 0.6086 - val_loss: 0.6485 - val_accuracy: 0.5562\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6137 - accuracy: 0.6086 - val_loss: 0.6479 - val_accuracy: 0.5562\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6130 - accuracy: 0.6086 - val_loss: 0.6474 - val_accuracy: 0.5562\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6123 - accuracy: 0.6086 - val_loss: 0.6468 - val_accuracy: 0.5562\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6117 - accuracy: 0.6086 - val_loss: 0.6462 - val_accuracy: 0.5562\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6110 - accuracy: 0.6086 - val_loss: 0.6456 - val_accuracy: 0.5562\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6102 - accuracy: 0.6086 - val_loss: 0.6451 - val_accuracy: 0.5562\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6094 - accuracy: 0.6086 - val_loss: 0.6447 - val_accuracy: 0.5562\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6088 - accuracy: 0.6086 - val_loss: 0.6442 - val_accuracy: 0.5562\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6081 - accuracy: 0.6086 - val_loss: 0.6436 - val_accuracy: 0.5562\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6073 - accuracy: 0.6086 - val_loss: 0.6431 - val_accuracy: 0.5562\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6067 - accuracy: 0.6086 - val_loss: 0.6425 - val_accuracy: 0.5562\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6059 - accuracy: 0.6086 - val_loss: 0.6420 - val_accuracy: 0.5562\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6052 - accuracy: 0.6086 - val_loss: 0.6415 - val_accuracy: 0.5562\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6044 - accuracy: 0.6086 - val_loss: 0.6410 - val_accuracy: 0.5562\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6038 - accuracy: 0.6086 - val_loss: 0.6405 - val_accuracy: 0.5562\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6030 - accuracy: 0.6086 - val_loss: 0.6400 - val_accuracy: 0.5562\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6022 - accuracy: 0.6086 - val_loss: 0.6393 - val_accuracy: 0.5562\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6015 - accuracy: 0.6086 - val_loss: 0.6386 - val_accuracy: 0.5562\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6007 - accuracy: 0.6086 - val_loss: 0.6379 - val_accuracy: 0.5562\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6002 - accuracy: 0.6086 - val_loss: 0.6373 - val_accuracy: 0.5562\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5992 - accuracy: 0.6086 - val_loss: 0.6367 - val_accuracy: 0.5562\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5984 - accuracy: 0.6086 - val_loss: 0.6359 - val_accuracy: 0.5562\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5975 - accuracy: 0.6086 - val_loss: 0.6352 - val_accuracy: 0.5562\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5969 - accuracy: 0.6086 - val_loss: 0.6348 - val_accuracy: 0.5562\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5960 - accuracy: 0.6086 - val_loss: 0.6343 - val_accuracy: 0.5562\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5951 - accuracy: 0.6086 - val_loss: 0.6335 - val_accuracy: 0.5562\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5944 - accuracy: 0.6086 - val_loss: 0.6327 - val_accuracy: 0.5562\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5935 - accuracy: 0.6086 - val_loss: 0.6321 - val_accuracy: 0.5562\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5927 - accuracy: 0.6086 - val_loss: 0.6316 - val_accuracy: 0.5562\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5919 - accuracy: 0.6086 - val_loss: 0.6312 - val_accuracy: 0.5562\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5915 - accuracy: 0.6086 - val_loss: 0.6308 - val_accuracy: 0.5562\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5905 - accuracy: 0.6086 - val_loss: 0.6300 - val_accuracy: 0.5562\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5896 - accuracy: 0.6086 - val_loss: 0.6294 - val_accuracy: 0.5562\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5888 - accuracy: 0.6086 - val_loss: 0.6290 - val_accuracy: 0.5562\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5882 - accuracy: 0.6086 - val_loss: 0.6286 - val_accuracy: 0.5562\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5874 - accuracy: 0.6086 - val_loss: 0.6279 - val_accuracy: 0.5562\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5866 - accuracy: 0.6086 - val_loss: 0.6275 - val_accuracy: 0.5562\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5857 - accuracy: 0.6086 - val_loss: 0.6270 - val_accuracy: 0.5562\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5849 - accuracy: 0.6086 - val_loss: 0.6263 - val_accuracy: 0.5562\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5841 - accuracy: 0.6648 - val_loss: 0.6255 - val_accuracy: 0.6573\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5832 - accuracy: 0.6929 - val_loss: 0.6250 - val_accuracy: 0.6573\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5825 - accuracy: 0.7041 - val_loss: 0.6246 - val_accuracy: 0.6517\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5817 - accuracy: 0.7041 - val_loss: 0.6238 - val_accuracy: 0.6517\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5807 - accuracy: 0.7041 - val_loss: 0.6231 - val_accuracy: 0.6517\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5800 - accuracy: 0.7022 - val_loss: 0.6222 - val_accuracy: 0.6517\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5792 - accuracy: 0.7060 - val_loss: 0.6216 - val_accuracy: 0.6517\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5783 - accuracy: 0.7079 - val_loss: 0.6212 - val_accuracy: 0.6461\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5775 - accuracy: 0.7079 - val_loss: 0.6209 - val_accuracy: 0.6517\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5769 - accuracy: 0.7060 - val_loss: 0.6201 - val_accuracy: 0.6517\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5762 - accuracy: 0.7041 - val_loss: 0.6200 - val_accuracy: 0.6517\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5751 - accuracy: 0.7060 - val_loss: 0.6191 - val_accuracy: 0.6517\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5744 - accuracy: 0.7060 - val_loss: 0.6182 - val_accuracy: 0.6517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5735 - accuracy: 0.7060 - val_loss: 0.6175 - val_accuracy: 0.6517\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5727 - accuracy: 0.7041 - val_loss: 0.6168 - val_accuracy: 0.6517\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5720 - accuracy: 0.7079 - val_loss: 0.6162 - val_accuracy: 0.6517\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5712 - accuracy: 0.7060 - val_loss: 0.6157 - val_accuracy: 0.6461\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5703 - accuracy: 0.7097 - val_loss: 0.6157 - val_accuracy: 0.6517\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5695 - accuracy: 0.7172 - val_loss: 0.6153 - val_accuracy: 0.6573\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5687 - accuracy: 0.7172 - val_loss: 0.6142 - val_accuracy: 0.6517\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5679 - accuracy: 0.7172 - val_loss: 0.6137 - val_accuracy: 0.6629\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5672 - accuracy: 0.7191 - val_loss: 0.6135 - val_accuracy: 0.6629\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5663 - accuracy: 0.7210 - val_loss: 0.6126 - val_accuracy: 0.6685\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5655 - accuracy: 0.7228 - val_loss: 0.6118 - val_accuracy: 0.6685\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5648 - accuracy: 0.7210 - val_loss: 0.6119 - val_accuracy: 0.6742\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5638 - accuracy: 0.7210 - val_loss: 0.6107 - val_accuracy: 0.6685\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.5630 - accuracy: 0.7210 - val_loss: 0.6096 - val_accuracy: 0.6685\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5622 - accuracy: 0.7210 - val_loss: 0.6096 - val_accuracy: 0.6742\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5615 - accuracy: 0.7266 - val_loss: 0.6091 - val_accuracy: 0.6854\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5606 - accuracy: 0.7303 - val_loss: 0.6083 - val_accuracy: 0.6742\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5598 - accuracy: 0.7247 - val_loss: 0.6074 - val_accuracy: 0.6798\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5591 - accuracy: 0.7303 - val_loss: 0.6063 - val_accuracy: 0.6742\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5581 - accuracy: 0.7303 - val_loss: 0.6056 - val_accuracy: 0.6854\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5574 - accuracy: 0.7341 - val_loss: 0.6051 - val_accuracy: 0.6910\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5565 - accuracy: 0.7360 - val_loss: 0.6042 - val_accuracy: 0.6910\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5556 - accuracy: 0.7378 - val_loss: 0.6037 - val_accuracy: 0.6854\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5553 - accuracy: 0.7416 - val_loss: 0.6046 - val_accuracy: 0.7022\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5540 - accuracy: 0.7453 - val_loss: 0.6035 - val_accuracy: 0.7022\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5533 - accuracy: 0.7416 - val_loss: 0.6015 - val_accuracy: 0.6966\n"
     ]
    }
   ],
   "source": [
    "#question 3\n",
    "\n",
    "def make_net5(number_features, \n",
    "             hidden_layers=1, \n",
    "             hidden_layer_neurones=3, \n",
    "             dropout=0.0, \n",
    "             learning_rate=0.003):\n",
    "    \n",
    "    \"\"\"Make TensorFlow neural net\"\"\"\n",
    "    \n",
    "    # Clear Tensorflow \n",
    "    K.clear_session()\n",
    "    \n",
    "    # Set up neural net\n",
    "    net = Sequential()\n",
    "    \n",
    "    # Add hidden hidden_layers using a loop\n",
    "    for i in range(hidden_layers+1):\n",
    "        # Add fully connected layer with ReLu activation\n",
    "        net.add(Dense(\n",
    "            hidden_layer_neurones, \n",
    "            input_dim=number_features,\n",
    "            activation='sigmoid'))\n",
    "        # Add droput layer\n",
    "        net.add(Dropout(dropout))\n",
    "    \n",
    "    # Add final sigmoid activation output\n",
    "    net.add(Dense(1, activation='sigmoid'))    \n",
    "    \n",
    "    # Compiling model\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    \n",
    "    net.compile(loss='binary_crossentropy', \n",
    "                optimizer=opt, \n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return net\n",
    "\n",
    "model5 = make_net5(10)\n",
    "#model3.summary()\n",
    "\n",
    "# def plot_training(history_dict):\n",
    "#     acc_values = history_dict['accuracy']\n",
    "#     val_acc_values = history_dict['val_accuracy']\n",
    "#     epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "#     plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "#     plt.plot(epochs, val_acc_values, 'b', label='Test accuracy')\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.xlabel('Epochs')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "def calculate_accuracy(model, X_train_sc, X_test_sc, y_train, y_test):\n",
    "    \"\"\"Calculate and print accuracy of trainign and test data fits\"\"\"    \n",
    "    \n",
    "    ### Get accuracy of fit to training data\n",
    "    probability = model.predict(X_train_sc)\n",
    "    y_pred_train = probability >= 0.5\n",
    "    y_pred_train = y_pred_train.flatten()\n",
    "    accuracy_train = np.mean(y_pred_train == y_train)\n",
    "    \n",
    "    ### Get accuracy of fit to test data\n",
    "    probability = model.predict(X_test_sc)\n",
    "    y_pred_test = probability >= 0.5\n",
    "    y_pred_test = y_pred_test.flatten()\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "\n",
    "    # Show acuracy\n",
    "    print (f'Training accuracy {accuracy_train:0.3f}')\n",
    "    print (f'Test accuracy {accuracy_test:0.3f}')\n",
    "    return y_pred_test\n",
    "# Define network\n",
    "number_features = x_train.shape[1]\n",
    "model5 = make_net5(number_features)\n",
    "\n",
    "x_train=np.asarray(x_train).astype(np.int)\n",
    "\n",
    "y_train=np.asarray(y_train).astype(np.int)\n",
    "### Train model (and stote training info in history)\n",
    "history5 = model5.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e03339ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbde8328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "Training accuracy 0.745\n",
      "Test accuracy 0.697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x29d6891e0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAGwCAYAAABSAee3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA29UlEQVR4nO3de3hU5bn38d8kkEmATDgmmUgMAQICAUVCIdDKQUGisjm0igUVFHBTqEgp4ka2Gq0k4lswWmoK1M3BQsFLi9WqHCwGbRENESwFiihBAhIDCOZASEhmvX8go2MCzGRmkpms7+e6nquZdbyDae7c93rWWhbDMAwBAICgFNLQAQAAgLojkQMAEMRI5AAABDESOQAAQYxEDgBAECORAwAQxEjkAAAEsSYNHYA3HA6HvvzyS0VGRspisTR0OAAADxmGoZKSEsXFxSkkxH+15blz51RZWen1ccLCwhQeHu6DiHwnqBP5l19+qfj4+IYOAwDgpYKCArVv394vxz537pwSE1qosKja62PFxsYqPz8/oJJ5UCfyyMhISdIXH3eQrQVXCdA43Tp9YkOHAPhNVdU5fZST6fx97g+VlZUqLKrWF3kdZIuse64oLnEooc9hVVZWksh95WI73dYixKv/OEAga9I0cH5hAP5SH5dHW0Ra1CKy7udxKDAv4QZ1IgcAwF3VhkPVXrxdpNpw+C4YHyKRAwBMwSFDDtU9k3uzrz/RjwYAIIhRkQMATMEhh7xpjnu3t/+QyAEAplBtGKo26t4e92Zff6K1DgBAEKMiBwCYQmOd7EYiBwCYgkOGqhthIqe1DgBAEKMiBwCYQmNtrVORAwBM4eKsdW+Gp44dO6a77rpLbdq0UbNmzXTdddcpLy/PuX7SpEmyWCwuo3///h6dg4ocAAA/OH36tAYOHKghQ4bo7bffVnR0tD7//HO1bNnSZbsRI0ZoxYoVzs9hYWEenYdEDgAwBce3w5v9PbFw4ULFx8e7JOkOHTrU2M5qtSo2NrbOcdFaBwCYQvW3s9a9GZJUXFzsMioqKmo93+uvv66UlBTdfvvtio6OVu/evbV8+fIa2+Xk5Cg6OlpdunTR1KlTVVRU5NH3RSIHAJhCteH9kKT4+HhFRUU5R2ZmZq3nO3TokLKzs5WUlKRNmzZp2rRpmjlzplavXu3cJi0tTWvWrNHWrVu1aNEi5ebmaujQoZf846A2tNYBAPBAQUGBbDab87PVaq11O4fDoZSUFGVkZEiSevfurb179yo7O1v33HOPJGncuHHO7ZOTk5WSkqKEhAS9+eabGjt2rFvxUJEDAEzB4YMhSTabzWVcKpHb7XZ1797dZVm3bt105MiRS8Zot9uVkJCggwcPuv19UZEDAEzBIYuqZfFqf08MHDhQBw4ccFn26aefKiEh4ZL7nDp1SgUFBbLb7W6fh4ocAAA/+NWvfqUdO3YoIyNDn332mdauXatly5ZpxowZkqTS0lLNmTNHH3zwgQ4fPqycnByNHDlSbdu21ZgxY9w+DxU5AMAUHMaF4c3+nujbt682bNigefPm6cknn1RiYqKysrI0YcIESVJoaKj27Nmj1atX68yZM7Lb7RoyZIjWr1+vyMhIt89DIgcAmEK1l631uux722236bbbbqt1XUREhDZt2lTneC6itQ4AQBCjIgcAmEJDVOT1gUQOADAFh2GRw/Bi1roX+/oTrXUAAIIYFTkAwBRorQMAEMSqFaJqLxrR1T6MxZdI5AAAUzC8vEZucI0cAAD4GhU5AMAUuEYOAEAQqzZCVG14cY3ci8e7+hOtdQAAghgVOQDAFByyyOFF/epQYJbkJHIAgCk01mvktNYBAAhiVOQAAFPwfrIbrXUAABrMhWvkXrw0hdY6AADwNSpyAIApOLx81jqz1gEAaEBcIwcAIIg5FNIo7yPnGjkAAEGMihwAYArVhkXVXryK1Jt9/YlEDgAwhWovJ7tV01oHAAC+RkUOADAFhxEihxez1h3MWgcAoOHQWgcAAAGHihwAYAoOeTfz3OG7UHyKRA4AMAXvHwgTmE3swIwKAAC4hUQOADCFi89a92Z46tixY7rrrrvUpk0bNWvWTNddd53y8vKc6w3DUHp6uuLi4hQREaHBgwdr7969Hp2DRA4AMIWL7yP3Znji9OnTGjhwoJo2baq3335b+/bt06JFi9SyZUvnNs8884wWL16sJUuWKDc3V7GxsRo2bJhKSkrcPg/XyAEApuD9288823fhwoWKj4/XihUrnMs6dOjg/NowDGVlZWn+/PkaO3asJGnVqlWKiYnR2rVr9d///d9unYeKHAAADxQXF7uMioqKWrd7/fXXlZKSottvv13R0dHq3bu3li9f7lyfn5+vwsJCDR8+3LnMarVq0KBB2r59u9vxkMgBAKZw8YEw3gxJio+PV1RUlHNkZmbWer5Dhw4pOztbSUlJ2rRpk6ZNm6aZM2dq9erVkqTCwkJJUkxMjMt+MTExznXuoLUOADAFh2GRw5v7yL/dt6CgQDabzbncarXWvr3DoZSUFGVkZEiSevfurb179yo7O1v33HOPczuLxTUmwzBqLLscKnIAADxgs9lcxqUSud1uV/fu3V2WdevWTUeOHJEkxcbGSlKN6ruoqKhGlX45JHIAgCk4vGyre/pAmIEDB+rAgQMuyz799FMlJCRIkhITExUbG6stW7Y411dWVmrbtm0aMGCA2+ehtQ4AMAXv337m2b6/+tWvNGDAAGVkZOiOO+7QRx99pGXLlmnZsmWSLrTUZ82apYyMDCUlJSkpKUkZGRlq1qyZxo8f7/Z5SOQAAPhB3759tWHDBs2bN09PPvmkEhMTlZWVpQkTJji3mTt3rsrLyzV9+nSdPn1a/fr10+bNmxUZGen2eUjkAABTqJZF1R4+1OWH+3vqtttu02233XbJ9RaLRenp6UpPT69zXCRyAIAp1Hdrvb4EZlQAAMAtVOQAAFOoVt3a49/fPxCRyAEAptBYW+skcgCAKdT3S1PqS2BGBQAA3EJFDgAwBaMO7xT/4f6BiEQOADAFWusAACDgUJEDAEzBV68xDTQkcgCAKVx8i5k3+weiwIwKAAC4hYocAGAKtNYBAAhiDoXI4UUj2pt9/SkwowIAAG6hIgcAmEK1YVG1F+1xb/b1JxI5AMAUuEYOAEAQM7x8+5nBk90AAICvUZEDAEyhWhZVe/HiE2/29ScSOQDAFByGd9e5HYYPg/EhWusAAAQxKnLU6uTxpnpxgV2579pUWR6iqzpWaPbiI0rqVS5Jujnuulr3m/K/x3T79BP1GCnguf8avE//NWS/YtuWSpIOH2ul1W/01kd74hUa6tDkMTvVr1eB7O1KVFYepo/3xWnZK3116kzzBo4c3nB4OdnNm339iUSOGkrOhGr2qCT1GlCip/50SC3bVun44TA1t1U7t/nz7n+77JO71aZnfx2vH9/6TX2HC3jsxOnmWv7Kj3SsyCZJunngp3rqgS26P32MTpxurqSEk3rpjd76vKC1WjSr1C9//oEWzNyiaU+ObtjA4RWHLHJ4cZ3bm339qcH/vHjhhReUmJio8PBw9enTR++//35Dh2R6L/8+Wm3jKjUnq0DX9D6r2PhK9f5JqeI6VDq3aR1d5TI+2BSlaweWyp5QeZkjA4Hhg08S9OGeeB39KkpHv4rSi3/pq/JzTdW9U5HKysP00KJblJPbUQWFLbX/ULSeXzNAXTucVHTr0oYOHaihQRP5+vXrNWvWLM2fP1+7du3ST37yE6WlpenIkSMNGZbp7dgcpS7XntVT93fQHT17aPqwLnprTetLbn/6RBN99Hebbr7zVD1GCfhGiMWhIT/6XOHW89r7eXSt2zRvVimHQyo9G1bP0cGXLj7ZzZsRiBq0tb548WJNnjxZU6ZMkSRlZWVp06ZNys7OVmZmZkOGZmrHj4Tpb6vbauz9J3TnA1/pwO5myn60vZqGGRp2++ka2295ubUiWlTrx7fQVkfwSLzqa/1+/usKa1qt8oqmemzJMH3xZasa2zVtUqX7f5arv3/YSWfPkciDGdfIfayyslJ5eXn6n//5H5flw4cP1/bt22vdp6KiQhUVFc7PxcXFfo3RrAyHlNSrXPfNOy5J6tyzXF8cCNebq9vWmsg3rWutoWNOKyw8QO/NAGpRUBilKelj1KJZpW7oc1j/M2WbZi281SWZh4Y69Ni0d2WxGMp6aWADRgtcWoP9eXHy5ElVV1crJibGZXlMTIwKCwtr3SczM1NRUVHOER8fXx+hmk7r6ColdDnnsiw+6ZyKjjWtse2eD5vr6OfhGjGetjqCS1V1qL4sitKnh9vpj6/21ecFrfXTm/Y614eGOvT4L/4ue7sSPfTbNKrxRsAhi/N563UaTHarncXi+g9jGEaNZRfNmzdP33zzjXMUFBTUR4im071vmQo+t7osO3bIquirztfYdtOf2yip11l16nGuxjogmFgkNW1y4c6Mi0m8fXSxfv3bNBWXhTdscPAJ49tZ63UdBoncVdu2bRUaGlqj+i4qKqpRpV9ktVpls9lcBnxv7P1F+s/HzfXn56N1LD9MW//SUm/9qY3+696TLtuVlYTovTeiqMYRdKaMzVXPpELFtClR4lVfa/LYXF17zXG9s6OTQkIcemL6O+ra4aQWLB+sEIuhVrazamU7qyah1Vc+OAKWV9V4Hd6clp6eLovF4jJiY2Od6ydNmlRjff/+/T3+vhrsGnlYWJj69OmjLVu2aMyYMc7lW7Zs0ahRoxoqLEjqel25HnsxXysy7VrzbKxi4ys17cljGjrW9fr4tr+2kgyLhoyued0cCGStosr1yNQctY46q7LyMB062loPL75ZefvaK6ZNiQb2vnDnzB+f2OCy36yFt+iTA3ENETKCVI8ePfTOO+84P4eGhrqsHzFihFasWOH8HBbm+SWcBp21Pnv2bN19991KSUlRamqqli1bpiNHjmjatGkNGRYk9R9WrP7DLj+Z8Ja7TumWu6jGEXz+34obLrnuq1ORGnLflHqMBvWlIWatN2nSxKUK/yGr1XrZ9W6dw6u9vTRu3DidOnVKTz75pI4fP67k5GS99dZbSkhIaMiwAACNUF3a4z/cX6p5x5TVapXVaq1tFx08eFBxcXGyWq3q16+fMjIy1LFjR+f6nJwcRUdHq2XLlho0aJAWLFig6Ojan2dwKQ0+2W369Ok6fPiwKioqlJeXpxtuuPRfygAANLT4+HiXO6gu9dyTfv36afXq1dq0aZOWL1+uwsJCDRgwQKdOXehkpqWlac2aNdq6dasWLVqk3NxcDR061OU2a3fwrHUAgCn46lnrBQUFLpOtL1WNp6WlOb/u2bOnUlNT1alTJ61atUqzZ8/WuHHjnOuTk5OVkpKihIQEvfnmmxo7dqzbcZHIAQCm4KvWel3vmmrevLl69uypgwcP1rrebrcrISHhkusvpcFb6wAAmEFFRYX2798vu91e6/pTp06poKDgkusvhUQOADCF+r6PfM6cOdq2bZvy8/P14Ycf6mc/+5mKi4s1ceJElZaWas6cOfrggw90+PBh5eTkaOTIkWrbtq3LLdnuoLUOADAFX7XW3XX06FH9/Oc/18mTJ9WuXTv1799fO3bsUEJCgsrLy7Vnzx6tXr1aZ86ckd1u15AhQ7R+/XpFRkZ6dB4SOQAAfrBu3bpLrouIiNCmTZt8ch4SOQDAFOq7Iq8vJHIAgCkYkle3nwXqi5pJ5AAAU2isFTmz1gEACGJU5AAAU2isFTmJHABgCo01kdNaBwAgiFGRAwBMobFW5CRyAIApGIZFhhfJ2Jt9/YnWOgAAQYyKHABgCr56H3mgIZEDAEyhsV4jp7UOAEAQoyIHAJhCY53sRiIHAJhCY22tk8gBAKbQWCtyrpEDABDEqMgBAKZgeNlaD9SKnEQOADAFQ5JheLd/IKK1DgBAEKMiBwCYgkMWWXiyGwAAwYlZ6wAAIOBQkQMATMFhWGThgTAAAAQnw/By1nqATluntQ4AQBCjIgcAmEJjnexGIgcAmAKJHACAINZYJ7txjRwAgCBGIgcAmMLFWeveDE+kp6fLYrG4jNjY2O/FYyg9PV1xcXGKiIjQ4MGDtXfvXo+/LxI5AMAULiRjixfD83P26NFDx48fd449e/Y41z3zzDNavHixlixZotzcXMXGxmrYsGEqKSnx6BwkcgAA/KRJkyaKjY11jnbt2km6UI1nZWVp/vz5Gjt2rJKTk7Vq1SqdPXtWa9eu9egcJHIAgCl4V41/N+O9uLjYZVRUVFzynAcPHlRcXJwSExN155136tChQ5Kk/Px8FRYWavjw4c5trVarBg0apO3bt3v0fZHIAQCmYPhgSFJ8fLyioqKcIzMzs9bz9evXT6tXr9amTZu0fPlyFRYWasCAATp16pQKCwslSTExMS77xMTEONe5i9vPAADwQEFBgWw2m/Oz1Wqtdbu0tDTn1z179lRqaqo6deqkVatWqX///pIki8X1ljbDMGosuxIqcgCAKfiqtW6z2VzGpRL5DzVv3lw9e/bUwYMHnbPXf1h9FxUV1ajSr4REDgAwB1/11uuooqJC+/fvl91uV2JiomJjY7Vlyxbn+srKSm3btk0DBgzw6Li01gEA5uDlI1rl4b5z5szRyJEjdfXVV6uoqEhPPfWUiouLNXHiRFksFs2aNUsZGRlKSkpSUlKSMjIy1KxZM40fP96j85DIAQDwg6NHj+rnP/+5Tp48qXbt2ql///7asWOHEhISJElz585VeXm5pk+frtOnT6tfv37avHmzIiMjPToPiRwAYAr1/T7ydevWXXa9xWJRenq60tPT6x6USOQAAJNorG8/Y7IbAABBjIocAGAOhsXjCWs19g9AJHIAgCnU9zXy+kJrHQCAIEZFDgAwB28f6hKgFTmJHABgCo111rpbifz55593+4AzZ86sczAAAMAzbiXyZ5991q2DWSwWEjkAIHAFaHvcG24l8vz8fH/HAQCAXzXW1nqdZ61XVlbqwIEDqqqq8mU8AAD4RwO//cxfPE7kZ8+e1eTJk9WsWTP16NFDR44ckXTh2vjTTz/t8wABAMCleZzI582bp08++UQ5OTkKDw93Lr/pppu0fv16nwYHAIDvWHwwAo/Ht5+99tprWr9+vfr37y+L5btvqnv37vr88899GhwAAD7TSO8j97giP3HihKKjo2ssLysrc0nsAADA/zxO5H379tWbb77p/HwxeS9fvlypqam+iwwAAF9qpJPdPG6tZ2ZmasSIEdq3b5+qqqr03HPPae/evfrggw+0bds2f8QIAID3GunbzzyuyAcMGKB//vOfOnv2rDp16qTNmzcrJiZGH3zwgfr06eOPGAEAwCXU6VnrPXv21KpVq3wdCwAAftNYX2Nap0ReXV2tDRs2aP/+/bJYLOrWrZtGjRqlJk14BwsAIEA10lnrHmfef//73xo1apQKCwvVtWtXSdKnn36qdu3a6fXXX1fPnj19HiQAAKidx9fIp0yZoh49eujo0aP6+OOP9fHHH6ugoEC9evXS/fff748YAQDw3sXJbt6MAORxRf7JJ59o586datWqlXNZq1attGDBAvXt29enwQEA4CsW48LwZv9A5HFF3rVrV3311Vc1lhcVFalz584+CQoAAJ9rpPeRu5XIi4uLnSMjI0MzZ87UK6+8oqNHj+ro0aN65ZVXNGvWLC1cuNDf8QIAgO9xq7XesmVLl8evGoahO+64w7nM+HZO/siRI1VdXe2HMAEA8FIjfSCMW4n83Xff9XccAAD4l5lvPxs0aJC/4wAAAHVQ5ye4nD17VkeOHFFlZaXL8l69enkdFAAAPmfmivz7Tpw4oXvvvVdvv/12reu5Rg4ACEiNNJF7fPvZrFmzdPr0ae3YsUMRERHauHGjVq1apaSkJL3++uv+iBEAgKCWmZkpi8WiWbNmOZdNmjRJFovFZfTv39/jY3tckW/dulV//etf1bdvX4WEhCghIUHDhg2TzWZTZmambr31Vo+DAADA7xpo1npubq6WLVtW66XnESNGaMWKFc7PYWFhHh/f44q8rKxM0dHRkqTWrVvrxIkTki68Ee3jjz/2OAAAAOrDxSe7eTM8VVpaqgkTJmj58uUuT0S9yGq1KjY21jlat27t8Tnq9GS3AwcOSJKuu+46LV26VMeOHdMf/vAH2e12jwMAACCYfP8hacXFxaqoqLjktjNmzNCtt96qm266qdb1OTk5io6OVpcuXTR16lQVFRV5HI/HrfVZs2bp+PHjkqTHH39cN998s9asWaOwsDCtXLnS4wAAAKgXPprsFh8f77L48ccfV3p6eo3N161bp48//li5ubm1Hi4tLU233367EhISlJ+fr0cffVRDhw5VXl6erFar22F5nMgnTJjg/Lp37946fPiw/vOf/+jqq69W27ZtPT0cAABBpaCgQDabzfm5tqRbUFCgBx98UJs3b1Z4eHitxxk3bpzz6+TkZKWkpCghIUFvvvmmxo4d63Y8db6P/KJmzZrp+uuv9/YwAAD4lUVevv3s2/+12Wwuibw2eXl5KioqUp8+fZzLqqur9d5772nJkiWqqKhQaGioyz52u10JCQk6ePCgR3G5lchnz57t9gEXL17sUQAAADQ2N954o/bs2eOy7N5779U111yjhx9+uEYSl6RTp06poKDA4/lmbiXyXbt2uXWw779YpT6N6dJTTSxNG+TcgL9dm+fe//+AYFRZel7b36mnk9Xj7WeRkZFKTk52Wda8eXO1adNGycnJKi0tVXp6un7605/Kbrfr8OHDeuSRR9S2bVuNGTPGo7B4aQoAwBwC6MluoaGh2rNnj1avXq0zZ87IbrdryJAhWr9+vSIjIz06ltfXyAEAwJXl5OQ4v46IiNCmTZt8clwSOQDAHAKoIvclEjkAwBTq+nS27+8fiDx+shsAAAgcVOQAAHNopK31OlXkL730kgYOHKi4uDh98cUXkqSsrCz99a9/9WlwAAD4jOGDEYA8TuTZ2dmaPXu2brnlFp05c0bV1dWSpJYtWyorK8vX8QEAgMvwOJH/7ne/0/LlyzV//nyXJ9OkpKTUeIoNAACBoiFeY1ofPL5Gnp+fr969e9dYbrVaVVZW5pOgAADwuXp8slt98rgiT0xM1O7du2ssf/vtt9W9e3dfxAQAgO810mvkHlfkDz30kGbMmKFz587JMAx99NFH+vOf/6zMzEz98Y9/9EeMAADgEjxO5Pfee6+qqqo0d+5cnT17VuPHj9dVV12l5557Tnfeeac/YgQAwGuN9YEwdbqPfOrUqZo6dapOnjwph8Oh6OhoX8cFAIBvNdL7yL16IEzbtm19FQcAAKgDjxN5YmLiZd87fujQIa8CAgDAL7y9hayxVOSzZs1y+Xz+/Hnt2rVLGzdu1EMPPeSruAAA8C1a6xc8+OCDtS7//e9/r507d3odEAAAcJ/P3n6WlpamV1991VeHAwDAt7iP/PJeeeUVtW7d2leHAwDAp7j97Fu9e/d2mexmGIYKCwt14sQJvfDCCz4NDgAAXJ7HiXz06NEun0NCQtSuXTsNHjxY11xzja/iAgAAbvAokVdVValDhw66+eabFRsb66+YAADwvUY6a92jyW5NmjTRL37xC1VUVPgrHgAA/KKxvsbU41nr/fr1065du/wRCwAA8JDH18inT5+uX//61zp69Kj69Omj5s2bu6zv1auXz4IDAMCnArSq9obbify+++5TVlaWxo0bJ0maOXOmc53FYpFhGLJYLKqurvZ9lAAAeKuRXiN3O5GvWrVKTz/9tPLz8/0ZDwAA8IDbidwwLvwpkpCQ4LdgAADwFx4II132rWcAAAQ0s7fWJalLly5XTOZff/21VwEBAAD3eZTIn3jiCUVFRfkrFgAA/IbWuqQ777xT0dHR/ooFAAD/acDWemZmph555BE9+OCDysrKunA4w9ATTzyhZcuW6fTp0+rXr59+//vfq0ePHh4d2+0HwnB9HAAAz+Xm5mrZsmU1nrPyzDPPaPHixVqyZIlyc3MVGxurYcOGqaSkxKPju53IL85aBwAgKDXA+8hLS0s1YcIELV++XK1atfouFMNQVlaW5s+fr7Fjxyo5OVmrVq3S2bNntXbtWo/O4XYidzgctNUBAEHLV89aLy4udhmXe//IjBkzdOutt+qmm25yWZ6fn6/CwkINHz7cucxqtWrQoEHavn27R9+Xx89aBwAgKPmoIo+Pj1dUVJRzZGZm1nq6devW6eOPP651fWFhoSQpJibGZXlMTIxznbs8ftY6AABmVlBQIJvN5vxstVpr3ebBBx/U5s2bFR4efslj/XD+2cXHnXuCRA4AMAcfzVq32Wwuibw2eXl5KioqUp8+fZzLqqur9d5772nJkiU6cOCApAuVud1ud25TVFRUo0q/ElrrAABTqM/3kd94443as2ePdu/e7RwpKSmaMGGCdu/erY4dOyo2NlZbtmxx7lNZWalt27ZpwIABHn1fVOQAAPhYZGSkkpOTXZY1b95cbdq0cS6fNWuWMjIylJSUpKSkJGVkZKhZs2YaP368R+cikQMAzCHAnrU+d+5clZeXa/r06c4HwmzevFmRkZEeHYdEDgAwhYZ+RGtOTo7r8SwWpaenKz093avjco0cAIAgRkUOADCHAGut+wqJHABgDo00kdNaBwAgiFGRAwBMwfLt8Gb/QEQiBwCYQyNtrZPIAQCm0NC3n/kL18gBAAhiVOQAAHOgtQ4AQJAL0GTsDVrrAAAEMSpyAIApNNbJbiRyAIA5NNJr5LTWAQAIYlTkAABToLUOAEAwo7UOAAACDRU5AMAUaK0DABDMGmlrnUQOADCHRprIuUYOAEAQoyIHAJgC18gBAAhmtNYBAECgoSIHAJiCxTBkMepeVnuzrz+RyAEA5kBrHQAABBoqcgCAKTBrHQCAYEZrHQAABBoSOQDAFC621r0ZnsjOzlavXr1ks9lks9mUmpqqt99+27l+0qRJslgsLqN///4ef1+01gEA5lDPrfX27dvr6aefVufOnSVJq1at0qhRo7Rr1y716NFDkjRixAitWLHCuU9YWJjHYZHIAQCmUN+T3UaOHOnyecGCBcrOztaOHTucidxqtSo2NrbuQYnWOgAAHikuLnYZFRUVV9ynurpa69atU1lZmVJTU53Lc3JyFB0drS5dumjq1KkqKiryOB4SOQDAHAwfDEnx8fGKiopyjszMzEuecs+ePWrRooWsVqumTZumDRs2qHv37pKktLQ0rVmzRlu3btWiRYuUm5uroUOHuvWHwffRWgcAmIYv7gUvKCiQzWZzfrZarZfctmvXrtq9e7fOnDmjV199VRMnTtS2bdvUvXt3jRs3zrldcnKyUlJSlJCQoDfffFNjx451Ox4SOQAAHrg4C90dYWFhzsluKSkpys3N1XPPPaelS5fW2NZutyshIUEHDx70KB4SOQDAHAzjwvBmf69DMC7ZOj916pQKCgpkt9s9OiaJHABgCvU9a/2RRx5RWlqa4uPjVVJSonXr1iknJ0cbN25UaWmp0tPT9dOf/lR2u12HDx/WI488orZt22rMmDEenYdEDgCAH3z11Ve6++67dfz4cUVFRalXr17auHGjhg0bpvLycu3Zs0erV6/WmTNnZLfbNWTIEK1fv16RkZEenYdEDgAwh3p+IMyLL754yXURERHatGmTF8F8h0QOADAFi+PC8Gb/QMR95AAABDEqctQw7pdfaeAt3yi+c4Uqz4Vo385menGBXUc/D5ckhTYxNOnh4+o7tET2hEqVFYdo1/uRejHDrq+/atrA0QNXdmJptU4uc+2ThraRumy+8Ctxf5+qWveLfjBEbe6h/glajfQ1piRy1NArtUxvrGyrT3c3cybtjD8f0tRBXVVRHiprhEOde5ZrbVaMDu0LV4uoak174ks9sTJfD6R1aejwAbdYO0lXvxD63YLvfZm0KdRl29Ltho4/6VDkUEs9RQd/qO9Z6/WlQf+0fO+99zRy5EjFxcXJYrHotddea8hw8K35Ezpqy8ut9cWn4Tq0L0KLfnW1YtqfV1KvcknS2ZJQzbuzk957o6WOfh6u/3zcXC/871Xqcm252l1V2cDRA24KlZq0tXw3Wn2XpF2Wt7WoJMdQsxSLwtqTyIPaxfvIvRkBqEETeVlZma699lotWbKkIcPAFTS3VUuSSs6EXnYbh0Mq++bS2wCBpPKIdPDmKn02skrH5lWr8mjtv6SrThkq/YehlqNI4ghMDdpaT0tLU1pamtvbV1RUuDwRp7i42B9hwYWh+9O/1L8/bK4vDkTUukVTq0P3PXJc725oqbOlJHIEvohki+KetCjsaouqvzZ08kWHDt9XrY4vh6pJS9eE/c3fDIU0F231RoDWegDIzMx0eeNMfHx8Q4fU6M3IOKbEbuXKnH51retDmxh6JPsLWUKkJfPa13N0QN20GBgi240hCk+yqHm/EMU/d+EP0G/+VvM39Zm/OhSVZlGIlUQe9Hz09rNAE1SJfN68efrmm2+co6CgoKFDatSmP3VUqcOLNfdnnXTyeFiN9aFNDM1felix8ZWad2dHqnEErZAIi8I7W1R5xPU39dldhiq/kFqODqpflTCZoJq1brVaL/u6OPiKoRkLjmnAiG/00M8666uCmv/mF5P4VYmVmvuzTio5HVQ/SoALR6WhinxDEde5JuwzrzkU3k0K70I13hg01tY6v31Rwy8zjmnImNNKvzdR5aUhatXuvCSprCRUledCFBJq6NHlh9W5Z7keuydRIaGGc5uSM6GqOk/1gsD21bPVanFDiJrGStVfSydfdMhRJrUc+V3Cri41VPyOoZhf8fPcaATA28/8gUSOGkZOOiVJ+u1fPndZ/ttZ8drycmu1s59X6s0XJhpmv/OpyzYP/bST/vVBi/oJFKijqiLpy0eqVXVGatJKiuhpUYeVoWpq/y6RF282JEOy3Uw1jsDWoIm8tLRUn332mfNzfn6+du/erdatW+vqq2ufXAX/uznu2suu/+po2BW3AQLZVZlXns/RamyIWo2lGm9MaK37wc6dOzVkyBDn59mzZ0uSJk6cqJUrVzZQVACARolHtPre4MGDZQToNQcAAIIB18gBAKZAax0AgGDmMC4Mb/YPQCRyAIA5NNJr5EzJBAAgiFGRAwBMwSIvr5H7LBLfIpEDAMyhkT7ZjdY6AABBjIocAGAK3H4GAEAwY9Y6AAAINFTkAABTsBiGLF5MWPNmX38ikQMAzMHx7fBm/wBEax0AgCBGRQ4AMAVa6wAABDNmrQMAEMQuPtnNm+GB7Oxs9erVSzabTTabTampqXr77be/F46h9PR0xcXFKSIiQoMHD9bevXs9/rZI5AAA+EH79u319NNPa+fOndq5c6eGDh2qUaNGOZP1M888o8WLF2vJkiXKzc1VbGyshg0bppKSEo/OQyIHAJjCxSe7eTM8MXLkSN1yyy3q0qWLunTpogULFqhFixbasWOHDMNQVlaW5s+fr7Fjxyo5OVmrVq3S2bNntXbtWo/OQyIHAJiDj1rrxcXFLqOiouKKp66urta6detUVlam1NRU5efnq7CwUMOHD3duY7VaNWjQIG3fvt2jb4tEDgCAB+Lj4xUVFeUcmZmZl9x2z549atGihaxWq6ZNm6YNGzaoe/fuKiwslCTFxMS4bB8TE+Nc5y5mrQMATMHiuDC82V+SCgoKZLPZnMutVusl9+natat2796tM2fO6NVXX9XEiRO1bdu2745pcX3LuWEYNZZdCYkcAGAOPnof+cVZ6O4ICwtT586dJUkpKSnKzc3Vc889p4cffliSVFhYKLvd7ty+qKioRpV+JbTWAQCoJ4ZhqKKiQomJiYqNjdWWLVuc6yorK7Vt2zYNGDDAo2NSkQMAzKGeHwjzyCOPKC0tTfHx8SopKdG6deuUk5OjjRs3ymKxaNasWcrIyFBSUpKSkpKUkZGhZs2aafz48R6dh0QOADCF+n5E61dffaW7775bx48fV1RUlHr16qWNGzdq2LBhkqS5c+eqvLxc06dP1+nTp9WvXz9t3rxZkZGRHp2HRA4AgB+8+OKLl11vsViUnp6u9PR0r85DIgcAmIOPJrsFGhI5AMAcDHn3TvHAzOMkcgCAOTTW15hy+xkAAEGMihwAYA6GvLxG7rNIfIpEDgAwh0Y62Y3WOgAAQYyKHABgDg5Jnr2PpOb+AYhEDgAwBWatAwCAgENFDgAwh0Y62Y1EDgAwh0aayGmtAwAQxKjIAQDm0EgrchI5AMAcuP0MAIDgxe1nAAAg4FCRAwDMgWvkAAAEMYchWbxIxo7ATOS01gEACGJU5AAAc6C1DgBAMPMykSswEzmtdQAAghgVOQDAHGitAwAQxByGvGqPM2sdAAD4GhU5AMAcDMeF4c3+AYhEDgAwB66RAwAQxLhGDgAAAg2JHABgDhdb694MD2RmZqpv376KjIxUdHS0Ro8erQMHDrhsM2nSJFksFpfRv39/j85DIgcAmIMhLxO5Z6fbtm2bZsyYoR07dmjLli2qqqrS8OHDVVZW5rLdiBEjdPz4ced46623PDoP18gBAPCDjRs3unxesWKFoqOjlZeXpxtuuMG53Gq1KjY2ts7noSIHAJiDj1rrxcXFLqOiosKt03/zzTeSpNatW7ssz8nJUXR0tLp06aKpU6eqqKjIo2+LRA4AMAeHw/shKT4+XlFRUc6RmZl5xVMbhqHZs2frxz/+sZKTk53L09LStGbNGm3dulWLFi1Sbm6uhg4d6vYfBxKtdQAAPFJQUCCbzeb8bLVar7jPL3/5S/3rX//SP/7xD5fl48aNc36dnJyslJQUJSQk6M0339TYsWPdiodEDgAwBx89EMZms7kk8it54IEH9Prrr+u9995T+/btL7ut3W5XQkKCDh486PbxSeQAAHOo5ye7GYahBx54QBs2bFBOTo4SExOvuM+pU6dUUFAgu93u9nm4Rg4AgB/MmDFDf/rTn7R27VpFRkaqsLBQhYWFKi8vlySVlpZqzpw5+uCDD3T48GHl5ORo5MiRatu2rcaMGeP2eajIAQDmUM+PaM3OzpYkDR482GX5ihUrNGnSJIWGhmrPnj1avXq1zpw5I7vdriFDhmj9+vWKjIx0+zwkcgCAKRiGQ4YXbzDzdF/jCq34iIgIbdq0qc7xXEQiBwCYg2F49+KTAH37GdfIAQAIYlTkAABzMLy8Rh6gFTmJHABgDg6HZKn7NXJ5cX3dn2itAwAQxKjIAQDmQGsdAIDgZTgcMrxorXtz65o/0VoHACCIUZEDAMyB1joAAEHMYUiWxpfIaa0DABDEqMgBAOZgGJK8uY88MCtyEjkAwBQMhyHDi9b6lV6C0lBI5AAAczAc8q4i5/YzAADgY1TkAABToLUOAEAwa6St9aBO5Bf/OqrSea/u8QcCWWUpP9xovCrLzkuqn2rX21xRpfO+C8aHgjqRl5SUSJL+obcaOBLAf3JuaOgIAP8rKSlRVFSUX44dFham2NhY/aPQ+1wRGxursLAwH0TlOxYjUJv+bnA4HPryyy8VGRkpi8XS0OGYQnFxseLj41VQUCCbzdbQ4QA+xc93/TMMQyUlJYqLi1NIiP/mX587d06VlZVeHycsLEzh4eE+iMh3groiDwkJUfv27Rs6DFOy2Wz8okOjxc93/fJXJf594eHhAZeAfYXbzwAACGIkcgAAghiJHB6xWq16/PHHZbVaGzoUwOf4+UYwCurJbgAAmB0VOQAAQYxEDgBAECORAwAQxEjkAAAEMRI53PbCCy8oMTFR4eHh6tOnj95///2GDgnwiffee08jR45UXFycLBaLXnvttYYOCXAbiRxuWb9+vWbNmqX58+dr165d+slPfqK0tDQdOXKkoUMDvFZWVqZrr71WS5YsaehQAI9x+xnc0q9fP11//fXKzs52LuvWrZtGjx6tzMzMBowM8C2LxaINGzZo9OjRDR0K4BYqclxRZWWl8vLyNHz4cJflw4cP1/bt2xsoKgCARCKHG06ePKnq6mrFxMS4LI+JiVFhYWEDRQUAkEjk8MAPXxVrGAavjwWABkYixxW1bdtWoaGhNarvoqKiGlU6AKB+kchxRWFhYerTp4+2bNnisnzLli0aMGBAA0UFAJCkJg0dAILD7NmzdffddyslJUWpqalatmyZjhw5omnTpjV0aIDXSktL9dlnnzk/5+fna/fu3WrdurWuvvrqBowMuDJuP4PbXnjhBT3zzDM6fvy4kpOT9eyzz+qGG25o6LAAr+Xk5GjIkCE1lk+cOFErV66s/4AAD5DIAQAIYlwjBwAgiJHIAQAIYiRyAACCGIkcAIAgRiIHACCIkcgBAAhiJHIAAIIYiRwAgCBGIge8lJ6eruuuu875edKkSRo9enS9x3H48GFZLBbt3r37ktt06NBBWVlZbh9z5cqVatmypdexWSwWvfbaa14fB0BNJHI0SpMmTZLFYpHFYlHTpk3VsWNHzZkzR2VlZX4/93PPPef2Yz3dSb4AcDm8NAWN1ogRI7RixQqdP39e77//vqZMmaKysjJlZ2fX2Pb8+fNq2rSpT84bFRXlk+MAgDuoyNFoWa1WxcbGKj4+XuPHj9eECROc7d2L7fD/+7//U8eOHWW1WmUYhr755hvdf//9io6Ols1m09ChQ/XJJ5+4HPfpp59WTEyMIiMjNXnyZJ07d85l/Q9b6w6HQwsXLlTnzp1ltVp19dVXa8GCBZKkxMRESVLv3r1lsVg0ePBg534rVqxQt27dFB4ermuuuUYvvPCCy3k++ugj9e7dW+Hh4UpJSdGuXbs8/jdavHixevbsqebNmys+Pl7Tp09XaWlpje1ee+01denSReHh4Ro2bJgKCgpc1r/xxhvq06ePwsPD1bFjRz3xxBOqqqryOB4AniORwzQiIiJ0/vx55+fPPvtML7/8sl599VVna/vWW29VYWGh3nrrLeXl5en666/XjTfeqK+//lqS9PLLL+vxxx/XggULtHPnTtnt9hoJ9ofmzZunhQsX6tFHH9W+ffu0du1axcTESLqQjCXpnXfe0fHjx/WXv/xFkrR8+XLNnz9fCxYs0P79+5WRkaFHH31Uq1atkiSVlZXptttuU9euXZWXl6f09HTNmTPH43+TkJAQPf/88/r3v/+tVatWaevWrZo7d67LNmfPntWCBQu0atUq/fOf/1RxcbHuvPNO5/pNmzbprrvu0syZM7Vv3z4tXbpUK1eudP6xAsDPDKARmjhxojFq1Cjn5w8//NBo06aNcccddxiGYRiPP/640bRpU6OoqMi5zd///nfDZrMZ586dczlWp06djKVLlxqGYRipqanGtGnTXNb369fPuPbaa2s9d3FxsWG1Wo3ly5fXGmd+fr4hydi1a5fL8vj4eGPt2rUuy37zm98YqamphmEYxtKlS43WrVsbZWVlzvXZ2dm1Huv7EhISjGefffaS619++WWjTZs2zs8rVqwwJBk7duxwLtu/f78hyfjwww8NwzCMn/zkJ0ZGRobLcV566SXDbrc7P0syNmzYcMnzAqg7rpGj0frb3/6mFi1aqKqqSufPn9eoUaP0u9/9zrk+ISFB7dq1c37Oy8tTaWmp2rRp43Kc8vJyff7555Kk/fv3a9q0aS7rU1NT9e6779Yaw/79+1VRUaEbb7zR7bhPnDihgoICTZ48WVOnTnUur6qqcl5/379/v6699lo1a9bMJQ5Pvfvuu8rIyNC+fftUXFysqqoqnTt3TmVlZWrevLkkqUmTJkpJSXHuc80116hly5bav3+/fvSjHykvL0+5ubkuFXh1dbXOnTuns2fPusQIwPdI5Gi0hgwZouzsbDVt2lRxcXE1JrNdTFQXORwO2e125eTk1DhWXW/BioiI8Hgfh8Mh6UJ7vV+/fi7rQkNDJUmGYdQpnu/74osvdMstt2jatGn6zW9+o9atW+sf//iHJk+e7HIJQrpw+9gPXVzmcDj0xBNPaOzYsTW2CQ8P9zpOAJdHIkej1bx5c3Xu3Nnt7a+//noVFhaqSZMm6tChQ63bdOvWTTt27NA999zjXLZjx45LHjMpKUkRERH6+9//rilTptRYHxYWJulCBXtRTEyMrrrqKh06dEgTJkyo9bjdu3fXSy+9pPLycucfC5eLozY7d+5UVVWVFi1apJCQC9NlXn755RrbVVVVaefOnfrRj34kSTpw4IDOnDmja665RtKFf7cDBw549G8NwHdI5MC3brrpJqWmpmr06NFauHChunbtqi+//FJvvfWWRo8erZSUFD344IOaOHGiUlJS9OMf/1hr1qzR3r171bFjx1qPGR4erocfflhz585VWFiYBg4cqBMnTmjv3r2aPHmyoqOjFRERoY0bN6p9+/YKDw9XVFSU0tPTNXPmTNlsNqWlpamiokI7d+7U6dOnNXv2bI0fP17z58/X5MmT9b//+786fPiwfvvb33r0/Xbq1ElVVVX63e9+p5EjR+qf//yn/vCHP9TYrmnTpnrggQf0/PPPq2nTpvrlL3+p/v37OxP7Y489pttuu03x8fG6/fbbFRISon/961/as2ePnnrqKc//QwDwCLPWgW9ZLBa99dZbuuGGG3TfffepS5cuuvPOO3X48GHnLPNx48bpscce08MPP6w+ffroiy++0C9+8YvLHvfRRx/Vr3/9az322GPq1q2bxo0bp6KiIkkXrj8///zzWrp0qeLi4jRq1ChJ0pQpU/THP/5RK1euVM+ePTVo0CCtXLnSebtaixYt9MYbb2jfvn3q3bu35s+fr4ULF3r0/V533XVavHixFi5cqOTkZK1Zs0aZmZk1tmvWrJkefvhhjR8/XqmpqYqIiNC6deuc62+++Wb97W9/05YtW9S3b1/1799fixcvVkJCgkfxAKgbi+GLi20AAKBBUJEDABDESOQAAAQxEjkAAEGMRA4AQBAjkQMAEMRI5AAABDESOQAAQYxEDgBAECORAwAQxEjkAAAEMRI5AABB7P8Di2f0iB5WStMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred5 = calculate_accuracy(model5, x_train, x_test, y_train, y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test,pred5))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2880f33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 3)                 36        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 12        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52\n",
      "Trainable params: 52\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/7zkwp1j916l4xty0z4xy6mgh0000gn/T/ipykernel_11954/786648204.py:78: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  x_train=np.asarray(x_train).astype(np.int)\n",
      "/var/folders/lw/7zkwp1j916l4xty0z4xy6mgh0000gn/T/ipykernel_11954/786648204.py:80: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_train=np.asarray(y_train).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 40ms/step - loss: 0.6927 - accuracy: 0.6086 - val_loss: 0.6928 - val_accuracy: 0.5562\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6917 - accuracy: 0.6086 - val_loss: 0.6921 - val_accuracy: 0.5562\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6904 - accuracy: 0.6086 - val_loss: 0.6914 - val_accuracy: 0.5562\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6890 - accuracy: 0.6086 - val_loss: 0.6907 - val_accuracy: 0.5562\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6875 - accuracy: 0.6086 - val_loss: 0.6900 - val_accuracy: 0.5562\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.6861 - accuracy: 0.6086 - val_loss: 0.6894 - val_accuracy: 0.5562\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6849 - accuracy: 0.6086 - val_loss: 0.6889 - val_accuracy: 0.5562\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6837 - accuracy: 0.6086 - val_loss: 0.6884 - val_accuracy: 0.5562\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6824 - accuracy: 0.6086 - val_loss: 0.6879 - val_accuracy: 0.5562\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6811 - accuracy: 0.6086 - val_loss: 0.6873 - val_accuracy: 0.5562\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.6795 - accuracy: 0.6086 - val_loss: 0.6863 - val_accuracy: 0.5562\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6769 - accuracy: 0.6086 - val_loss: 0.6846 - val_accuracy: 0.5562\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.6718 - accuracy: 0.6086 - val_loss: 0.6823 - val_accuracy: 0.5562\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6633 - accuracy: 0.6086 - val_loss: 0.6774 - val_accuracy: 0.5562\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6537 - accuracy: 0.6086 - val_loss: 0.6700 - val_accuracy: 0.5562\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6413 - accuracy: 0.6086 - val_loss: 0.6643 - val_accuracy: 0.5562\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.6342 - accuracy: 0.6086 - val_loss: 0.6608 - val_accuracy: 0.5562\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6290 - accuracy: 0.6086 - val_loss: 0.6596 - val_accuracy: 0.5562\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6260 - accuracy: 0.6086 - val_loss: 0.6594 - val_accuracy: 0.5562\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6245 - accuracy: 0.6086 - val_loss: 0.6606 - val_accuracy: 0.5562\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6230 - accuracy: 0.6086 - val_loss: 0.6616 - val_accuracy: 0.5562\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6217 - accuracy: 0.6086 - val_loss: 0.6614 - val_accuracy: 0.5562\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6209 - accuracy: 0.6086 - val_loss: 0.6605 - val_accuracy: 0.5562\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6196 - accuracy: 0.6086 - val_loss: 0.6607 - val_accuracy: 0.5562\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6186 - accuracy: 0.6086 - val_loss: 0.6606 - val_accuracy: 0.5562\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6179 - accuracy: 0.6086 - val_loss: 0.6606 - val_accuracy: 0.5562\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6169 - accuracy: 0.6086 - val_loss: 0.6594 - val_accuracy: 0.5562\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.6161 - accuracy: 0.6086 - val_loss: 0.6586 - val_accuracy: 0.5562\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6151 - accuracy: 0.6086 - val_loss: 0.6587 - val_accuracy: 0.5562\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6144 - accuracy: 0.6086 - val_loss: 0.6586 - val_accuracy: 0.5562\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6137 - accuracy: 0.6086 - val_loss: 0.6587 - val_accuracy: 0.5562\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6128 - accuracy: 0.6086 - val_loss: 0.6583 - val_accuracy: 0.5562\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6119 - accuracy: 0.6086 - val_loss: 0.6573 - val_accuracy: 0.5562\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6111 - accuracy: 0.6086 - val_loss: 0.6569 - val_accuracy: 0.5562\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6102 - accuracy: 0.6086 - val_loss: 0.6569 - val_accuracy: 0.5562\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6095 - accuracy: 0.6086 - val_loss: 0.6563 - val_accuracy: 0.5562\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6086 - accuracy: 0.6086 - val_loss: 0.6549 - val_accuracy: 0.5562\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6079 - accuracy: 0.6086 - val_loss: 0.6538 - val_accuracy: 0.5562\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6073 - accuracy: 0.6086 - val_loss: 0.6532 - val_accuracy: 0.5562\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6065 - accuracy: 0.6086 - val_loss: 0.6529 - val_accuracy: 0.5562\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6058 - accuracy: 0.6086 - val_loss: 0.6530 - val_accuracy: 0.5562\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.6051 - accuracy: 0.6086 - val_loss: 0.6521 - val_accuracy: 0.5562\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6044 - accuracy: 0.6086 - val_loss: 0.6517 - val_accuracy: 0.5562\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6038 - accuracy: 0.6086 - val_loss: 0.6512 - val_accuracy: 0.6348\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.6033 - accuracy: 0.7041 - val_loss: 0.6506 - val_accuracy: 0.6348\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6028 - accuracy: 0.7060 - val_loss: 0.6502 - val_accuracy: 0.6348\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6022 - accuracy: 0.7060 - val_loss: 0.6499 - val_accuracy: 0.6348\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6018 - accuracy: 0.7041 - val_loss: 0.6497 - val_accuracy: 0.6404\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6017 - accuracy: 0.7022 - val_loss: 0.6495 - val_accuracy: 0.6404\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.6010 - accuracy: 0.7022 - val_loss: 0.6488 - val_accuracy: 0.6404\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6005 - accuracy: 0.7022 - val_loss: 0.6481 - val_accuracy: 0.6348\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6002 - accuracy: 0.7041 - val_loss: 0.6479 - val_accuracy: 0.6348\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5996 - accuracy: 0.7041 - val_loss: 0.6475 - val_accuracy: 0.6292\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5991 - accuracy: 0.7022 - val_loss: 0.6471 - val_accuracy: 0.6292\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5986 - accuracy: 0.7041 - val_loss: 0.6468 - val_accuracy: 0.6292\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5982 - accuracy: 0.7041 - val_loss: 0.6464 - val_accuracy: 0.6292\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5978 - accuracy: 0.7041 - val_loss: 0.6461 - val_accuracy: 0.6236\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5974 - accuracy: 0.7060 - val_loss: 0.6458 - val_accuracy: 0.6236\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5970 - accuracy: 0.7060 - val_loss: 0.6455 - val_accuracy: 0.6348\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5965 - accuracy: 0.7041 - val_loss: 0.6451 - val_accuracy: 0.6348\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5963 - accuracy: 0.7041 - val_loss: 0.6445 - val_accuracy: 0.6292\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5957 - accuracy: 0.7060 - val_loss: 0.6441 - val_accuracy: 0.6292\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5952 - accuracy: 0.7060 - val_loss: 0.6440 - val_accuracy: 0.6292\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5948 - accuracy: 0.7060 - val_loss: 0.6438 - val_accuracy: 0.6292\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5946 - accuracy: 0.7004 - val_loss: 0.6435 - val_accuracy: 0.6404\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5940 - accuracy: 0.6985 - val_loss: 0.6432 - val_accuracy: 0.6348\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5936 - accuracy: 0.6985 - val_loss: 0.6430 - val_accuracy: 0.6348\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5935 - accuracy: 0.6985 - val_loss: 0.6429 - val_accuracy: 0.6404\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5929 - accuracy: 0.6966 - val_loss: 0.6424 - val_accuracy: 0.6292\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5922 - accuracy: 0.7004 - val_loss: 0.6418 - val_accuracy: 0.6292\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5919 - accuracy: 0.7041 - val_loss: 0.6413 - val_accuracy: 0.6180\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5918 - accuracy: 0.7041 - val_loss: 0.6411 - val_accuracy: 0.6180\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5912 - accuracy: 0.7041 - val_loss: 0.6409 - val_accuracy: 0.6180\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5910 - accuracy: 0.7022 - val_loss: 0.6407 - val_accuracy: 0.6236\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5903 - accuracy: 0.7022 - val_loss: 0.6402 - val_accuracy: 0.6180\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5899 - accuracy: 0.7041 - val_loss: 0.6400 - val_accuracy: 0.6180\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5896 - accuracy: 0.7041 - val_loss: 0.6399 - val_accuracy: 0.6236\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5890 - accuracy: 0.7022 - val_loss: 0.6395 - val_accuracy: 0.6236\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5885 - accuracy: 0.7022 - val_loss: 0.6392 - val_accuracy: 0.6236\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5881 - accuracy: 0.7022 - val_loss: 0.6390 - val_accuracy: 0.6236\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5875 - accuracy: 0.7022 - val_loss: 0.6388 - val_accuracy: 0.6236\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5871 - accuracy: 0.7060 - val_loss: 0.6385 - val_accuracy: 0.6292\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5867 - accuracy: 0.7022 - val_loss: 0.6381 - val_accuracy: 0.6348\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5864 - accuracy: 0.7079 - val_loss: 0.6378 - val_accuracy: 0.6236\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5857 - accuracy: 0.7060 - val_loss: 0.6374 - val_accuracy: 0.6236\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5853 - accuracy: 0.7079 - val_loss: 0.6370 - val_accuracy: 0.6236\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5849 - accuracy: 0.7060 - val_loss: 0.6367 - val_accuracy: 0.6236\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5844 - accuracy: 0.7079 - val_loss: 0.6365 - val_accuracy: 0.6236\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5839 - accuracy: 0.7079 - val_loss: 0.6362 - val_accuracy: 0.6292\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5834 - accuracy: 0.7041 - val_loss: 0.6360 - val_accuracy: 0.6348\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5832 - accuracy: 0.7022 - val_loss: 0.6356 - val_accuracy: 0.6348\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5827 - accuracy: 0.7041 - val_loss: 0.6351 - val_accuracy: 0.6348\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5822 - accuracy: 0.7041 - val_loss: 0.6347 - val_accuracy: 0.6348\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5818 - accuracy: 0.7041 - val_loss: 0.6345 - val_accuracy: 0.6348\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5812 - accuracy: 0.7041 - val_loss: 0.6341 - val_accuracy: 0.6348\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5807 - accuracy: 0.7060 - val_loss: 0.6337 - val_accuracy: 0.6348\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.5803 - accuracy: 0.7060 - val_loss: 0.6333 - val_accuracy: 0.6292\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5798 - accuracy: 0.7041 - val_loss: 0.6329 - val_accuracy: 0.6292\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5794 - accuracy: 0.7041 - val_loss: 0.6325 - val_accuracy: 0.6292\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5792 - accuracy: 0.7041 - val_loss: 0.6323 - val_accuracy: 0.6236\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5784 - accuracy: 0.7079 - val_loss: 0.6320 - val_accuracy: 0.6236\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5780 - accuracy: 0.7097 - val_loss: 0.6317 - val_accuracy: 0.6236\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5775 - accuracy: 0.7079 - val_loss: 0.6313 - val_accuracy: 0.6292\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5770 - accuracy: 0.7116 - val_loss: 0.6309 - val_accuracy: 0.6292\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5766 - accuracy: 0.7116 - val_loss: 0.6306 - val_accuracy: 0.6292\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5760 - accuracy: 0.7116 - val_loss: 0.6304 - val_accuracy: 0.6292\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5756 - accuracy: 0.7097 - val_loss: 0.6300 - val_accuracy: 0.6292\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.5754 - accuracy: 0.7097 - val_loss: 0.6297 - val_accuracy: 0.6348\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 0.5748 - accuracy: 0.7097 - val_loss: 0.6290 - val_accuracy: 0.6292\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5745 - accuracy: 0.7116 - val_loss: 0.6288 - val_accuracy: 0.6292\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5736 - accuracy: 0.7079 - val_loss: 0.6284 - val_accuracy: 0.6292\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5733 - accuracy: 0.7079 - val_loss: 0.6279 - val_accuracy: 0.6292\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5726 - accuracy: 0.7135 - val_loss: 0.6276 - val_accuracy: 0.6292\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5722 - accuracy: 0.7097 - val_loss: 0.6274 - val_accuracy: 0.6348\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.5717 - accuracy: 0.7097 - val_loss: 0.6273 - val_accuracy: 0.6348\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5713 - accuracy: 0.7079 - val_loss: 0.6270 - val_accuracy: 0.6404\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5709 - accuracy: 0.7097 - val_loss: 0.6267 - val_accuracy: 0.6404\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5700 - accuracy: 0.7079 - val_loss: 0.6261 - val_accuracy: 0.6348\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5695 - accuracy: 0.7097 - val_loss: 0.6256 - val_accuracy: 0.6404\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5697 - accuracy: 0.7060 - val_loss: 0.6254 - val_accuracy: 0.6348\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5687 - accuracy: 0.7079 - val_loss: 0.6250 - val_accuracy: 0.6404\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5683 - accuracy: 0.7097 - val_loss: 0.6248 - val_accuracy: 0.6404\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5676 - accuracy: 0.7079 - val_loss: 0.6245 - val_accuracy: 0.6404\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5671 - accuracy: 0.7097 - val_loss: 0.6242 - val_accuracy: 0.6404\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5665 - accuracy: 0.7079 - val_loss: 0.6241 - val_accuracy: 0.6404\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5664 - accuracy: 0.7079 - val_loss: 0.6239 - val_accuracy: 0.6517\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5654 - accuracy: 0.7079 - val_loss: 0.6232 - val_accuracy: 0.6404\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5648 - accuracy: 0.7079 - val_loss: 0.6228 - val_accuracy: 0.6404\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5649 - accuracy: 0.7116 - val_loss: 0.6225 - val_accuracy: 0.6404\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5640 - accuracy: 0.7154 - val_loss: 0.6222 - val_accuracy: 0.6461\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5634 - accuracy: 0.7154 - val_loss: 0.6219 - val_accuracy: 0.6461\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5628 - accuracy: 0.7097 - val_loss: 0.6216 - val_accuracy: 0.6461\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5624 - accuracy: 0.7097 - val_loss: 0.6214 - val_accuracy: 0.6461\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5619 - accuracy: 0.7135 - val_loss: 0.6210 - val_accuracy: 0.6404\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5613 - accuracy: 0.7172 - val_loss: 0.6209 - val_accuracy: 0.6348\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5607 - accuracy: 0.7172 - val_loss: 0.6206 - val_accuracy: 0.6348\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5604 - accuracy: 0.7172 - val_loss: 0.6203 - val_accuracy: 0.6348\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5596 - accuracy: 0.7191 - val_loss: 0.6200 - val_accuracy: 0.6404\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5592 - accuracy: 0.7116 - val_loss: 0.6199 - val_accuracy: 0.6517\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5588 - accuracy: 0.7097 - val_loss: 0.6195 - val_accuracy: 0.6461\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5580 - accuracy: 0.7116 - val_loss: 0.6191 - val_accuracy: 0.6404\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5575 - accuracy: 0.7116 - val_loss: 0.6188 - val_accuracy: 0.6461\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5570 - accuracy: 0.7116 - val_loss: 0.6184 - val_accuracy: 0.6404\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5567 - accuracy: 0.7116 - val_loss: 0.6182 - val_accuracy: 0.6404\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5558 - accuracy: 0.7135 - val_loss: 0.6176 - val_accuracy: 0.6404\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5553 - accuracy: 0.7172 - val_loss: 0.6173 - val_accuracy: 0.6404\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5549 - accuracy: 0.7154 - val_loss: 0.6170 - val_accuracy: 0.6404\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5542 - accuracy: 0.7135 - val_loss: 0.6165 - val_accuracy: 0.6404\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5538 - accuracy: 0.7154 - val_loss: 0.6161 - val_accuracy: 0.6404\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5533 - accuracy: 0.7172 - val_loss: 0.6157 - val_accuracy: 0.6404\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5526 - accuracy: 0.7172 - val_loss: 0.6154 - val_accuracy: 0.6348\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5524 - accuracy: 0.7135 - val_loss: 0.6150 - val_accuracy: 0.6404\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5518 - accuracy: 0.7135 - val_loss: 0.6146 - val_accuracy: 0.6517\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5510 - accuracy: 0.7135 - val_loss: 0.6138 - val_accuracy: 0.6461\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5504 - accuracy: 0.7135 - val_loss: 0.6129 - val_accuracy: 0.6404\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5499 - accuracy: 0.7172 - val_loss: 0.6122 - val_accuracy: 0.6404\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5495 - accuracy: 0.7172 - val_loss: 0.6116 - val_accuracy: 0.6517\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5486 - accuracy: 0.7135 - val_loss: 0.6111 - val_accuracy: 0.6461\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5479 - accuracy: 0.7172 - val_loss: 0.6105 - val_accuracy: 0.6461\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5473 - accuracy: 0.7172 - val_loss: 0.6099 - val_accuracy: 0.6461\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5469 - accuracy: 0.7191 - val_loss: 0.6095 - val_accuracy: 0.6461\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5462 - accuracy: 0.7154 - val_loss: 0.6091 - val_accuracy: 0.6461\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5456 - accuracy: 0.7154 - val_loss: 0.6086 - val_accuracy: 0.6461\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5454 - accuracy: 0.7191 - val_loss: 0.6079 - val_accuracy: 0.6461\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5448 - accuracy: 0.7172 - val_loss: 0.6076 - val_accuracy: 0.6517\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5440 - accuracy: 0.7154 - val_loss: 0.6071 - val_accuracy: 0.6573\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5431 - accuracy: 0.7191 - val_loss: 0.6068 - val_accuracy: 0.6461\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5426 - accuracy: 0.7191 - val_loss: 0.6065 - val_accuracy: 0.6461\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5423 - accuracy: 0.7135 - val_loss: 0.6060 - val_accuracy: 0.6461\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5415 - accuracy: 0.7135 - val_loss: 0.6056 - val_accuracy: 0.6517\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5418 - accuracy: 0.7154 - val_loss: 0.6053 - val_accuracy: 0.6629\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5404 - accuracy: 0.7191 - val_loss: 0.6050 - val_accuracy: 0.6629\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5399 - accuracy: 0.7135 - val_loss: 0.6044 - val_accuracy: 0.6629\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.5392 - accuracy: 0.7135 - val_loss: 0.6040 - val_accuracy: 0.6685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5383 - accuracy: 0.7172 - val_loss: 0.6033 - val_accuracy: 0.6742\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5376 - accuracy: 0.7135 - val_loss: 0.6025 - val_accuracy: 0.6742\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5369 - accuracy: 0.7172 - val_loss: 0.6020 - val_accuracy: 0.6742\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5361 - accuracy: 0.7172 - val_loss: 0.6014 - val_accuracy: 0.6742\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5357 - accuracy: 0.7172 - val_loss: 0.6005 - val_accuracy: 0.6685\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5350 - accuracy: 0.7172 - val_loss: 0.5996 - val_accuracy: 0.6685\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5335 - accuracy: 0.7210 - val_loss: 0.5987 - val_accuracy: 0.6685\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5327 - accuracy: 0.7172 - val_loss: 0.5983 - val_accuracy: 0.6798\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5316 - accuracy: 0.7154 - val_loss: 0.5967 - val_accuracy: 0.6742\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5306 - accuracy: 0.7303 - val_loss: 0.5955 - val_accuracy: 0.6685\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.5296 - accuracy: 0.7303 - val_loss: 0.5944 - val_accuracy: 0.6742\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5284 - accuracy: 0.7303 - val_loss: 0.5934 - val_accuracy: 0.6798\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5274 - accuracy: 0.7341 - val_loss: 0.5918 - val_accuracy: 0.6798\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5256 - accuracy: 0.7360 - val_loss: 0.5904 - val_accuracy: 0.6966\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.5245 - accuracy: 0.7397 - val_loss: 0.5886 - val_accuracy: 0.7022\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.5232 - accuracy: 0.7434 - val_loss: 0.5874 - val_accuracy: 0.7079\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.5216 - accuracy: 0.7397 - val_loss: 0.5855 - val_accuracy: 0.7135\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5199 - accuracy: 0.7453 - val_loss: 0.5845 - val_accuracy: 0.7135\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5186 - accuracy: 0.7472 - val_loss: 0.5834 - val_accuracy: 0.7191\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5177 - accuracy: 0.7509 - val_loss: 0.5828 - val_accuracy: 0.7191\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5168 - accuracy: 0.7547 - val_loss: 0.5812 - val_accuracy: 0.7079\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5148 - accuracy: 0.7509 - val_loss: 0.5801 - val_accuracy: 0.7079\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5136 - accuracy: 0.7491 - val_loss: 0.5787 - val_accuracy: 0.7079\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5117 - accuracy: 0.7509 - val_loss: 0.5778 - val_accuracy: 0.7022\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5103 - accuracy: 0.7509 - val_loss: 0.5765 - val_accuracy: 0.7079\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.5088 - accuracy: 0.7491 - val_loss: 0.5753 - val_accuracy: 0.7191\n"
     ]
    }
   ],
   "source": [
    "def make_net6(number_features, \n",
    "             hidden_layers=1, \n",
    "             hidden_layer_neurones=3, \n",
    "             dropout=0.0, \n",
    "             learning_rate=0.003):\n",
    "    \n",
    "    \"\"\"Make TensorFlow neural net\"\"\"\n",
    "    \n",
    "    # Clear Tensorflow \n",
    "    K.clear_session()\n",
    "    \n",
    "    # Set up neural net\n",
    "    net = Sequential()\n",
    "    \n",
    "    # Add hidden hidden_layers using a loop\n",
    "    for i in range(hidden_layers+1):\n",
    "        # Add fully connected layer with ReLu activation\n",
    "        net.add(Dense(\n",
    "            hidden_layer_neurones, \n",
    "            input_dim=number_features,\n",
    "            activation='relu'))\n",
    "        # Add droput layer\n",
    "        net.add(Dropout(dropout))\n",
    "    \n",
    "    # Add final sigmoid activation output\n",
    "    net.add(Dense(1, activation='sigmoid'))    \n",
    "    \n",
    "    # Compiling model\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    \n",
    "    net.compile(loss='binary_crossentropy', \n",
    "                optimizer=opt, \n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return net\n",
    "\n",
    "model6 = make_net6(11)\n",
    "model6.summary()\n",
    "\n",
    "def plot_training(history_dict):\n",
    "    acc_values = history_dict['accuracy']\n",
    "    val_acc_values = history_dict['val_accuracy']\n",
    "    epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc_values, 'b', label='Test accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def calculate_accuracy(model, X_train_sc, X_test_sc, y_train, y_test):\n",
    "    \"\"\"Calculate and print accuracy of trainign and test data fits\"\"\"    \n",
    "    \n",
    "    ### Get accuracy of fit to training data\n",
    "    probability = model.predict(X_train_sc)\n",
    "    y_pred_train = probability >= 0.5\n",
    "    y_pred_train = y_pred_train.flatten()\n",
    "    accuracy_train = np.mean(y_pred_train == y_train)\n",
    "    \n",
    "    ### Get accuracy of fit to test data\n",
    "    probability = model.predict(X_test_sc)\n",
    "    y_pred_test = probability >= 0.5\n",
    "    y_pred_test = y_pred_test.flatten()\n",
    "    accuracy_test = np.mean(y_pred_test == y_test)\n",
    "\n",
    "    # Show acuracy\n",
    "    print (f'Training accuracy {accuracy_train:0.3f}')\n",
    "    print (f'Test accuracy {accuracy_test:0.3f}')\n",
    "    return y_pred_test\n",
    "\n",
    "# Define network\n",
    "number_features = x_train.shape[1]\n",
    "model6 = make_net6(number_features)\n",
    "\n",
    "x_train=np.asarray(x_train).astype(np.int)\n",
    "\n",
    "y_train=np.asarray(y_train).astype(np.int)\n",
    "### Train model (and stote training info in history)\n",
    "history6 = model6.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69c8d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 7ms/step\n",
      "Training accuracy 0.749\n",
      "Test accuracy 0.719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x29f8c4f10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred6 = calculate_accuracy(model6,x_train, x_test, y_train, y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test,pred6))\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
